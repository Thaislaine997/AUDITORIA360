# ğŸ”§ Monitoramento e Alertas - AUDITORIA360

## ğŸ¯ Objetivo

Este documento descreve a estratÃ©gia completa de observabilidade da AUDITORIA360, incluindo monitoramento de aplicaÃ§Ã£o, infraestrutura, alertas e dashboards operacionais.

## ğŸ“Š Stack de Observabilidade

### Componentes Principais
- **ğŸ“ˆ Prometheus**: Coleta de mÃ©tricas
- **ğŸ“Š Grafana**: VisualizaÃ§Ã£o e dashboards
- **ğŸ“ Loki**: AgregaÃ§Ã£o de logs
- **ğŸ” Jaeger**: Distributed tracing
- **âš ï¸ AlertManager**: GestÃ£o de alertas

### IntegraÃ§Ã£o com Cloud
- **â˜ï¸ Cloudflare Analytics**: MÃ©tricas de CDN
- **ğŸ—„ï¸ PostgreSQL Monitoring**: MÃ©tricas de banco
- **ğŸ”´ Redis Monitoring**: Performance de cache
- **ğŸ³ Docker Stats**: MÃ©tricas de containers

## ğŸ“ˆ MÃ©tricas Principais

### MÃ©tricas de AplicaÃ§Ã£o

#### Performance HTTP
```prometheus
# Tempo de resposta por endpoint
http_request_duration_seconds{method="GET", endpoint="/api/funcionarios"}

# Taxa de requests por segundo
rate(http_requests_total[5m])

# Taxa de erro 5xx
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m])
```

#### MÃ©tricas de NegÃ³cio
```prometheus
# Auditorias realizadas por hora
auditoria360_auditorias_total

# Irregularidades detectadas
auditoria360_irregularidades_total

# UsuÃ¡rios ativos
auditoria360_usuarios_ativos

# Uploads processados
auditoria360_uploads_processados_total

# RelatÃ³rios gerados
auditoria360_relatorios_gerados_total
```

#### MÃ©tricas de Sistema
```prometheus
# CPU usage
cpu_usage_percent

# Memory usage
memory_usage_percent

# Disk usage
disk_usage_percent

# Network I/O
network_bytes_total
```

### MÃ©tricas de Banco de Dados

```sql
-- ConexÃµes ativas
SELECT count(*) FROM pg_stat_activity WHERE state = 'active';

-- Queries lentas
SELECT query, mean_exec_time 
FROM pg_stat_statements 
WHERE mean_exec_time > 1000 
ORDER BY mean_exec_time DESC;

-- Tamanho das tabelas
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

## ğŸš¨ Alertas CrÃ­ticos

### Alertas de Infraestrutura

#### CPU Alto
```yaml
alert: HighCPUUsage
expr: cpu_usage_percent > 80
for: 5m
labels:
  severity: warning
annotations:
  summary: "CPU usage alto no servidor {{ $labels.instance }}"
  description: "CPU em {{ $value }}% por mais de 5 minutos"
```

#### MemÃ³ria Esgotada
```yaml
alert: HighMemoryUsage
expr: memory_usage_percent > 90
for: 2m
labels:
  severity: critical
annotations:
  summary: "MemÃ³ria crÃ­tica no servidor {{ $labels.instance }}"
  description: "Uso de memÃ³ria em {{ $value }}%"
```

#### Disco Cheio
```yaml
alert: DiskSpaceRunningOut
expr: disk_usage_percent > 85
for: 5m
labels:
  severity: warning
annotations:
  summary: "EspaÃ§o em disco baixo"
  description: "Apenas {{ $value }}% de espaÃ§o livre"
```

### Alertas de AplicaÃ§Ã£o

#### Taxa de Erro Alta
```yaml
alert: HighErrorRate
expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
for: 2m
labels:
  severity: critical
annotations:
  summary: "Taxa de erro HTTP alta"
  description: "{{ $value }} erros por segundo"
```

#### LatÃªncia Alta
```yaml
alert: HighLatency
expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
for: 5m
labels:
  severity: warning
annotations:
  summary: "LatÃªncia alta detectada"
  description: "P95 latÃªncia: {{ $value }}s"
```

#### Banco IndisponÃ­vel
```yaml
alert: DatabaseDown
expr: up{job="postgresql"} == 0
for: 1m
labels:
  severity: critical
annotations:
  summary: "Banco de dados indisponÃ­vel"
  description: "PostgreSQL nÃ£o estÃ¡ respondendo"
```

## ğŸ“Š Dashboards Operacionais

### Dashboard Principal - AUDITORIA360

#### SeÃ§Ã£o 1: Overview Geral
- **ğŸ”„ Status da AplicaÃ§Ã£o**: Up/Down status
- **ğŸ“Š Requests/sec**: Taxa de requisiÃ§Ãµes
- **â±ï¸ Response Time**: Tempo mÃ©dio de resposta
- **âŒ Error Rate**: Taxa de erros 5xx
- **ğŸ‘¥ UsuÃ¡rios Ativos**: UsuÃ¡rios logados atualmente

#### SeÃ§Ã£o 2: Performance
- **ğŸ“ˆ CPU Usage**: Uso de CPU por servidor
- **ğŸ’¾ Memory Usage**: Consumo de memÃ³ria
- **ğŸ’¿ Disk I/O**: OperaÃ§Ãµes de disco
- **ğŸŒ Network**: TrÃ¡fego de rede

#### SeÃ§Ã£o 3: MÃ©tricas de NegÃ³cio
- **ğŸ” Auditorias por Hora**: Volume de auditorias
- **âš ï¸ Irregularidades**: DetecÃ§Ãµes por perÃ­odo
- **ğŸ“„ RelatÃ³rios Gerados**: RelatÃ³rios por tipo
- **ğŸ“¤ Uploads**: Volume de arquivos processados

### Dashboard de Banco de Dados

#### PostgreSQL Metrics
- **ğŸ”Œ ConexÃµes**: Ativas/MÃ¡ximo
- **ğŸ“Š QPS**: Queries por segundo
- **â±ï¸ Query Time**: Tempo mÃ©dio de queries
- **ğŸ”’ Locks**: Locks ativos
- **ğŸ’¾ Cache Hit Ratio**: Taxa de acerto do cache

### Dashboard de Infrastructure

#### Docker Containers
- **ğŸ“¦ Container Status**: Up/Down por container
- **ğŸ’¾ Resource Usage**: CPU/Memory por container
- **ğŸ“Š Container Logs**: Logs em tempo real
- **ğŸ”„ Restart Count**: Contagem de restarts

## ğŸ”” ConfiguraÃ§Ã£o de NotificaÃ§Ãµes

### Canais de Alertas

#### Slack Integration
```yaml
slack_configs:
  - api_url: 'https://hooks.slack.com/services/...'
    channel: '#ops-alerts'
    title: 'AUDITORIA360 Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
```

#### Email Alerts
```yaml
email_configs:
  - to: 'ops-team@auditoria360.com.br'
    from: 'alerts@auditoria360.com.br'
    subject: 'AUDITORIA360 Alert: {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Alert: {{ .Annotations.summary }}
      Description: {{ .Annotations.description }}
      {{ end }}
```

#### WhatsApp Business (via Twilio)
```python
# IntegraÃ§Ã£o para alertas crÃ­ticos
def send_whatsapp_alert(message, severity):
    if severity == 'critical':
        client = Client(account_sid, auth_token)
        message = client.messages.create(
            body=f"ğŸš¨ AUDITORIA360 CRÃTICO: {message}",
            from_='whatsapp:+14155238886',
            to='whatsapp:+5511999999999'
        )
```

### EscalaÃ§Ã£o de Alertas

#### NÃ­vel 1: Avisos (Warning)
- **Canais**: Slack #dev-alerts
- **HorÃ¡rio**: 8h Ã s 18h
- **FrequÃªncia**: A cada 30 minutos

#### NÃ­vel 2: CrÃ­tico (Critical)
- **Canais**: Slack #ops-alerts + Email + SMS
- **HorÃ¡rio**: 24/7
- **FrequÃªncia**: Imediato + a cada 15 minutos

#### NÃ­vel 3: EmergÃªncia (Emergency)
- **Canais**: Todos + WhatsApp + LigaÃ§Ã£o
- **HorÃ¡rio**: 24/7
- **FrequÃªncia**: Imediato + a cada 5 minutos

## ğŸ“ Logging Strategy

### Estrutura de Logs

#### Formato JSON Estruturado
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "logger": "auditoria360.api",
  "message": "Auditoria iniciada",
  "request_id": "req_abc123",
  "user_id": 456,
  "client_id": "empresa_123",
  "endpoint": "/api/auditorias",
  "method": "POST",
  "response_time": 234,
  "status_code": 201
}
```

#### NÃ­veis de Log
- **DEBUG**: InformaÃ§Ãµes detalhadas para desenvolvimento
- **INFO**: OperaÃ§Ãµes normais da aplicaÃ§Ã£o
- **WARNING**: SituaÃ§Ãµes que requerem atenÃ§Ã£o
- **ERROR**: Erros que nÃ£o interrompem a aplicaÃ§Ã£o
- **CRITICAL**: Erros que podem interromper o serviÃ§o

### AgregaÃ§Ã£o com Loki

```yaml
# promtail.yml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
- job_name: auditoria360
  static_configs:
  - targets:
      - localhost
    labels:
      job: auditoria360
      __path__: /var/log/auditoria360/*.log
```

## ğŸ” Tracing com Jaeger

### InstrumentaÃ§Ã£o de CÃ³digo

```python
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# ConfiguraÃ§Ã£o do tracer
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

jaeger_exporter = JaegerExporter(
    agent_host_name="jaeger",
    agent_port=14268,
)

span_processor = BatchSpanProcessor(jaeger_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# InstrumentaÃ§Ã£o de funÃ§Ãµes
@tracer.start_as_current_span("processo_auditoria")
def processar_auditoria(funcionario_id):
    with tracer.start_as_current_span("validar_dados") as span:
        span.set_attribute("funcionario.id", funcionario_id)
        # lÃ³gica de validaÃ§Ã£o
        
    with tracer.start_as_current_span("calcular_valores"):
        # cÃ¡lculos da auditoria
        pass
```

## ğŸ“± Health Checks

### Endpoints de Status

```python
@app.get("/health")
async def health_check():
    """Health check bÃ¡sico."""
    return {"status": "healthy", "timestamp": datetime.utcnow()}

@app.get("/ready")
async def readiness_check():
    """Verifica se aplicaÃ§Ã£o estÃ¡ pronta."""
    checks = await run_readiness_checks()
    
    if all(check["healthy"] for check in checks.values()):
        return {"status": "ready", "checks": checks}
    else:
        raise HTTPException(
            status_code=503,
            detail={"status": "not_ready", "checks": checks}
        )

@app.get("/metrics")
async def metrics():
    """MÃ©tricas para Prometheus."""
    return Response(
        generate_latest(REGISTRY),
        media_type="text/plain"
    )
```

### Monitoramento Externo

```bash
#!/bin/bash
# Script de monitoramento externo

ENDPOINT="https://auditoria360.com.br/health"
EXPECTED_STATUS="healthy"

response=$(curl -s "$ENDPOINT" | jq -r '.status')

if [ "$response" != "$EXPECTED_STATUS" ]; then
    echo "CRITICAL: Health check failed - Status: $response"
    # Enviar alerta
    exit 2
else
    echo "OK: Application healthy"
    exit 0
fi
```

## ğŸš€ Deployment Monitoring

### Blue-Green Deployment Monitoring

```yaml
# Monitor durante deploy
deployment_monitor:
  pre_deploy:
    - check_database_connectivity
    - verify_migrations
    - validate_config
  
  during_deploy:
    - monitor_error_rates
    - track_response_times
    - watch_resource_usage
  
  post_deploy:
    - run_smoke_tests
    - verify_all_endpoints
    - check_business_metrics
```

## ğŸ“‹ Runbooks

### Incident Response

#### High CPU Usage
1. **Identificar causa**: Verificar top processes
2. **Avaliar impacto**: Checar mÃ©tricas de resposta
3. **AÃ§Ã£o imediata**: Scale horizontal se necessÃ¡rio
4. **InvestigaÃ§Ã£o**: Analisar logs para processos anÃ´malos
5. **ResoluÃ§Ã£o**: Otimizar queries ou adicionar recursos

#### Database Connection Issues
1. **Verificar conectividade**: `pg_isready`
2. **Checar pool de conexÃµes**: Monitorar conexÃµes ativas
3. **Restart se necessÃ¡rio**: Reiniciar aplicaÃ§Ã£o
4. **EscalaÃ§Ã£o**: Contatar DBA se problema persistir

---

ğŸ’¡ **Lembre-se**: Observabilidade Ã© fundamental para manter a AUDITORIA360 funcionando com excelÃªncia 24/7.

ğŸš¨ **Em caso de dÃºvidas**: Consulte o [Troubleshooting Guide](TROUBLESHOOTING_GUIDE.md) ou escalonate para a equipe de SRE.