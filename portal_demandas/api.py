"""
Portal Demandas FastAPI Application
Comprehensive API for managing demands/tickets with SQLAlchemy + Neon PostgreSQL
"""

import logging
import json
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from typing import List, Optional

from fastapi import Depends, FastAPI, HTTPException, Query, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import asc, desc, or_
from sqlalchemy.orm import Session

from portal_demandas.db import TicketComment as TicketCommentDB
from portal_demandas.db import (
    TicketDB,
    ContabilidadeDB,
    EmpresaDB, 
    ControleMensalDB,
    TarefaControleDB,
    TemplateControleDB,
    TemplateControleTarefaDB,
    ProcessamentosFolhaDB,
    HistoricoAnalisesRiscoDB,
    get_db,
    init_portal_db,
)
from portal_demandas.models import (
    Ticket,
    TicketCategoria,
    TicketComment,
    TicketCreate,
    TicketListResponse,
    TicketPrioridade,
    TicketStats,
    TicketStatus,
    TicketUpdate,
    # Controle Mensal models
    ControleMensalDetalhado,
    ControleMensalResponse,
    ControleMensalSumario,
    Tarefa,
    TemplateControle,
    TemplateControleCreate,
    TemplateAplicacao,
    # Payroll Audit models
    FuncionarioDivergencia,
    ProcessamentoFolhaResponse,
    AuditoriaFolhaRequest,
    # Risk Analysis models
    RiscoDetalhado,
    AnaliseRiscoResponse,
    AnaliseRiscoRequest,
    HistoricoAnaliseRisco,
)

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI lifespan event handler"""
    # Startup
    try:
        init_portal_db()
        logger.info("Portal demandas database initialized")
    except Exception as e:
        logger.error(f"Failed to initialize database: {e}")

    yield

    # Shutdown (if needed)
    logger.info("Portal demandas API shutting down")


# Create FastAPI app with lifespan
app = FastAPI(
    title="Portal Demandas API",
    description="API para gerenciamento de demandas e tickets do AUDITORIA360",
    version="1.0.0",
    lifespan=lifespan,
    tags_metadata=[
        {"name": "tickets", "description": "Operaﾃｧﾃｵes com tickets"},
        {"name": "comments", "description": "Comentﾃ｡rios dos tickets"},
        {"name": "stats", "description": "Estatﾃｭsticas e relatﾃｳrios"},
        {"name": "controle-mensal", "description": "Controles mensais das empresas"},
        {"name": "templates", "description": "Templates para controles recorrentes"},
        {"name": "folha-pagamento", "description": "Auditoria inteligente da folha de pagamento com IA"},
        {"name": "riscos", "description": "Consultor de Riscos - Anﾃ｡lise preditiva e identificaﾃｧﾃ｣o de riscos"},
    ],
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure properly for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Health check
@app.get("/health", tags=["health"])
def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "portal_demandas",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "version": "1.0.0",
    }


# Ticket CRUD operations
@app.post("/tickets/", response_model=Ticket, tags=["tickets"])
def criar_ticket(ticket: TicketCreate, db: Session = Depends(get_db)):
    """
    Criar um novo ticket
    """
    try:
        # Create database ticket
        db_ticket = TicketDB(
            titulo=ticket.titulo,
            descricao=ticket.descricao,
            etapa=ticket.etapa,
            prazo=ticket.prazo,
            responsavel=ticket.responsavel,
            prioridade=ticket.prioridade.value,
            categoria=ticket.categoria.value,
            tags=ticket.tags,
            tempo_estimado=ticket.tempo_estimado,
            criado_em=datetime.now(timezone.utc),
            atualizado_em=datetime.now(timezone.utc),
        )

        db.add(db_ticket)
        db.commit()
        db.refresh(db_ticket)

        # Log creation
        logger.info(f"Ticket created: ID={db_ticket.id}, Titulo='{db_ticket.titulo}'")

        return Ticket.model_validate(db_ticket)

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to create ticket: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao criar ticket: {str(e)}")


@app.get("/tickets/{ticket_id}", response_model=Ticket, tags=["tickets"])
def obter_ticket(ticket_id: int, db: Session = Depends(get_db)):
    """
    Obter um ticket especﾃｭfico por ID
    """
    db_ticket = db.query(TicketDB).filter(TicketDB.id == ticket_id).first()
    if not db_ticket:
        raise HTTPException(status_code=404, detail="Ticket nﾃ｣o encontrado")

    return Ticket.model_validate(db_ticket)


@app.get("/tickets/", response_model=TicketListResponse, tags=["tickets"])
def listar_tickets(
    page: int = Query(1, ge=1, description="Nﾃｺmero da pﾃ｡gina"),
    per_page: int = Query(
        10, ge=1, le=50, description="Itens por pﾃ｡gina (mﾃ｡ximo 50 para performance)"
    ),
    status: Optional[List[TicketStatus]] = Query(
        None, description="Filtrar por status"
    ),
    prioridade: Optional[List[TicketPrioridade]] = Query(
        None, description="Filtrar por prioridade"
    ),
    categoria: Optional[List[TicketCategoria]] = Query(
        None, description="Filtrar por categoria"
    ),
    responsavel: Optional[str] = Query(None, description="Filtrar por responsﾃ｡vel"),
    etapa: Optional[str] = Query(None, description="Filtrar por etapa"),
    search: Optional[str] = Query(None, description="Buscar no tﾃｭtulo e descriﾃｧﾃ｣o"),
    sort_by: str = Query("criado_em", description="Campo para ordenaﾃｧﾃ｣o"),
    sort_order: str = Query("desc", description="Ordem: asc ou desc"),
    db: Session = Depends(get_db),
):
    """
    Listar tickets com filtros e paginaﾃｧﾃ｣o - PERFORMANCE OPTIMIZED
    Reduced maximum per_page from 100 to 50 for better performance
    """
    import time

    start_time = time.time()

    try:
        # Build query
        query = db.query(TicketDB)

        # Apply filters
        if status:
            query = query.filter(TicketDB.status.in_([s.value for s in status]))

        if prioridade:
            query = query.filter(TicketDB.prioridade.in_([p.value for p in prioridade]))

        if categoria:
            query = query.filter(TicketDB.categoria.in_([c.value for c in categoria]))

        if responsavel:
            query = query.filter(TicketDB.responsavel.ilike(f"%{responsavel}%"))

        if etapa:
            query = query.filter(TicketDB.etapa.ilike(f"%{etapa}%"))

        if search:
            search_filter = or_(
                TicketDB.titulo.ilike(f"%{search}%"),
                TicketDB.descricao.ilike(f"%{search}%"),
            )
            query = query.filter(search_filter)

        # Apply sorting
        if hasattr(TicketDB, sort_by):
            sort_column = getattr(TicketDB, sort_by)
            if sort_order.lower() == "desc":
                query = query.order_by(desc(sort_column))
            else:
                query = query.order_by(asc(sort_column))

        # Get total count
        total = query.count()

        # Apply pagination
        offset = (page - 1) * per_page
        tickets = query.offset(offset).limit(per_page).all()

        # Convert to Pydantic models
        ticket_list = [Ticket.model_validate(ticket) for ticket in tickets]

        # Calculate processing time
        processing_time = time.time() - start_time

        logger.info(
            f"Ticket listing completed in {processing_time:.3f}s (page {page}, {len(ticket_list)} items)"
        )

        response = TicketListResponse.create(
            tickets=ticket_list, total=total, page=page, per_page=per_page
        )

        # Add performance metadata if available
        if hasattr(response, "__dict__"):
            response.__dict__["_performance"] = {
                "processing_time_seconds": processing_time,
                "optimization_level": "enhanced",
            }

        return response

    except Exception as e:
        logger.error(f"Failed to list tickets: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao listar tickets: {str(e)}")


@app.patch("/tickets/{ticket_id}", response_model=Ticket, tags=["tickets"])
def atualizar_ticket(
    ticket_id: int, ticket_update: TicketUpdate, db: Session = Depends(get_db)
):
    """
    Atualizar um ticket existente
    """
    # Find ticket
    db_ticket = db.query(TicketDB).filter(TicketDB.id == ticket_id).first()
    if not db_ticket:
        raise HTTPException(status_code=404, detail="Ticket nﾃ｣o encontrado")

    try:
        # Update fields
        update_data = ticket_update.dict(exclude_unset=True)

        for field, value in update_data.items():
            if hasattr(db_ticket, field) and value is not None:
                # Handle enum fields
                if field in ["status", "prioridade", "categoria"] and hasattr(
                    value, "value"
                ):
                    setattr(db_ticket, field, value.value)
                else:
                    setattr(db_ticket, field, value)

        # Update timestamp
        db_ticket.atualizado_em = datetime.now(timezone.utc)

        db.commit()
        db.refresh(db_ticket)

        logger.info(f"Ticket updated: ID={ticket_id}")

        return Ticket.model_validate(db_ticket)

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to update ticket {ticket_id}: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao atualizar ticket: {str(e)}"
        )


@app.delete("/tickets/{ticket_id}", tags=["tickets"])
def deletar_ticket(ticket_id: int, db: Session = Depends(get_db)):
    """
    Deletar um ticket
    """
    db_ticket = db.query(TicketDB).filter(TicketDB.id == ticket_id).first()
    if not db_ticket:
        raise HTTPException(status_code=404, detail="Ticket nﾃ｣o encontrado")

    try:
        # Delete related comments first
        db.query(TicketCommentDB).filter(
            TicketCommentDB.ticket_id == ticket_id
        ).delete()

        # Delete ticket
        db.delete(db_ticket)
        db.commit()

        logger.info(f"Ticket deleted: ID={ticket_id}")

        return {"message": "Ticket deletado com sucesso"}

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to delete ticket {ticket_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Erro ao deletar ticket: {str(e)}")


# Comments endpoints
@app.post(
    "/tickets/{ticket_id}/comments/", response_model=TicketComment, tags=["comments"]
)
def adicionar_comentario(
    ticket_id: int, comment: TicketComment, db: Session = Depends(get_db)
):
    """
    Adicionar comentﾃ｡rio a um ticket
    """
    # Verify ticket exists
    ticket_exists = db.query(TicketDB).filter(TicketDB.id == ticket_id).first()
    if not ticket_exists:
        raise HTTPException(status_code=404, detail="Ticket nﾃ｣o encontrado")

    try:
        db_comment = TicketCommentDB(
            ticket_id=ticket_id,
            autor=comment.autor,
            comentario=comment.comentario,
            tipo=comment.tipo,
            criado_em=datetime.now(timezone.utc),
        )

        db.add(db_comment)
        db.commit()
        db.refresh(db_comment)

        return TicketComment.model_validate(db_comment)

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to add comment to ticket {ticket_id}: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao adicionar comentﾃ｡rio: {str(e)}"
        )


@app.get(
    "/tickets/{ticket_id}/comments/",
    response_model=List[TicketComment],
    tags=["comments"],
)
def listar_comentarios(ticket_id: int, db: Session = Depends(get_db)):
    """
    Listar comentﾃ｡rios de um ticket
    """
    comments = (
        db.query(TicketCommentDB)
        .filter(TicketCommentDB.ticket_id == ticket_id)
        .order_by(TicketCommentDB.criado_em.desc())
        .all()
    )

    return [TicketComment.model_validate(comment) for comment in comments]


# Statistics endpoints with performance optimization
@app.get("/stats/", response_model=TicketStats, tags=["stats"])
def obter_estatisticas(db: Session = Depends(get_db)):
    """
    Obter estatﾃｭsticas dos tickets - PERFORMANCE OPTIMIZED
    Target: <0.5s response time (was 1.5s)
    """
    import time

    start_time = time.time()

    try:
        # Use single query with aggregations for better performance
        from sqlalchemy import case, func

        # Single query to get all statistics at once
        stats_query = db.query(
            func.count(TicketDB.id).label("total"),
            func.sum(case((TicketDB.status == "pendente", 1), else_=0)).label(
                "pendentes"
            ),
            func.sum(case((TicketDB.status == "em_andamento", 1), else_=0)).label(
                "em_andamento"
            ),
            func.sum(case((TicketDB.status == "concluido", 1), else_=0)).label(
                "concluidos"
            ),
            func.sum(case((TicketDB.status == "cancelado", 1), else_=0)).label(
                "cancelados"
            ),
            # Priority counts
            func.sum(case((TicketDB.prioridade == "baixa", 1), else_=0)).label(
                "prioridade_baixa"
            ),
            func.sum(case((TicketDB.prioridade == "media", 1), else_=0)).label(
                "prioridade_media"
            ),
            func.sum(case((TicketDB.prioridade == "alta", 1), else_=0)).label(
                "prioridade_alta"
            ),
            func.sum(case((TicketDB.prioridade == "critica", 1), else_=0)).label(
                "prioridade_critica"
            ),
            # Category counts
            func.sum(case((TicketDB.categoria == "geral", 1), else_=0)).label(
                "categoria_geral"
            ),
            func.sum(case((TicketDB.categoria == "auditoria", 1), else_=0)).label(
                "categoria_auditoria"
            ),
            func.sum(case((TicketDB.categoria == "folha", 1), else_=0)).label(
                "categoria_folha"
            ),
            func.sum(case((TicketDB.categoria == "documentos", 1), else_=0)).label(
                "categoria_documentos"
            ),
            func.sum(case((TicketDB.categoria == "cct", 1), else_=0)).label(
                "categoria_cct"
            ),
            func.sum(case((TicketDB.categoria == "sistema", 1), else_=0)).label(
                "categoria_sistema"
            ),
            # Average completion time for completed tickets
            func.avg(
                case((TicketDB.status == "concluido", TicketDB.tempo_gasto), else_=None)
            ).label("tempo_medio"),
        ).first()

        # Build response from single query result
        por_prioridade = {
            "baixa": int(stats_query.prioridade_baixa or 0),
            "media": int(stats_query.prioridade_media or 0),
            "alta": int(stats_query.prioridade_alta or 0),
            "critica": int(stats_query.prioridade_critica or 0),
        }

        por_categoria = {
            "geral": int(stats_query.categoria_geral or 0),
            "auditoria": int(stats_query.categoria_auditoria or 0),
            "folha": int(stats_query.categoria_folha or 0),
            "documentos": int(stats_query.categoria_documentos or 0),
            "cct": int(stats_query.categoria_cct or 0),
            "sistema": int(stats_query.categoria_sistema or 0),
        }

        # Calculate processing time
        processing_time = time.time() - start_time

        result = TicketStats(
            total=int(stats_query.total or 0),
            pendentes=int(stats_query.pendentes or 0),
            em_andamento=int(stats_query.em_andamento or 0),
            concluidos=int(stats_query.concluidos or 0),
            cancelados=int(stats_query.cancelados or 0),
            por_prioridade=por_prioridade,
            por_categoria=por_categoria,
            tempo_medio_conclusao=(
                float(stats_query.tempo_medio) if stats_query.tempo_medio else None
            ),
        )

        logger.info(f"Portal stats generated in {processing_time:.3f}s")

        if processing_time > 0.5:
            logger.warning(f"Portal stats took {processing_time:.3f}s (target: <0.5s)")

        return result

    except Exception as e:
        logger.error(f"Failed to get statistics: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao obter estatﾃｭsticas: {str(e)}"
        )


# Bulk operations
@app.patch("/tickets/bulk/status", tags=["tickets"])
def atualizar_status_bulk(
    ticket_ids: List[int], new_status: TicketStatus, db: Session = Depends(get_db)
):
    """
    Atualizar status de mﾃｺltiplos tickets
    """
    try:
        updated_count = (
            db.query(TicketDB)
            .filter(TicketDB.id.in_(ticket_ids))
            .update(
                {
                    "status": new_status.value,
                    "atualizado_em": datetime.now(timezone.utc),
                },
                synchronize_session=False,
            )
        )

        db.commit()

        logger.info(
            f"Bulk status update: {updated_count} tickets updated to {new_status.value}"
        )

        return {
            "message": f"{updated_count} tickets atualizados para status '{new_status.value}'",
            "updated_count": updated_count,
        }

    except Exception as e:
        db.rollback()
        logger.error(f"Failed bulk status update: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro na atualizaﾃｧﾃ｣o em lote: {str(e)}"
        )


# ===== CONTROLE MENSAL ENDPOINTS =====

@app.get("/v1/controles/{ano}/{mes}", response_model=ControleMensalResponse, tags=["controle-mensal"])
def obter_controles_do_mes(
    ano: int, mes: int, db: Session = Depends(get_db)
):
    """
    Obter todos os controles mensais do ano/mﾃｪs especificado
    Endpoint principal que substitui as chamadas diretas ao Supabase
    """
    try:
        # Get user's accounting firm ID (this would come from auth in production)
        # For now, we'll assume contabilidade_id = 1 for testing
        contabilidade_id = 1  # TODO: Get from authentication context
        
        # Query controls with companies and tasks
        controles_query = (
            db.query(ControleMensalDB, EmpresaDB.nome.label('nome_empresa'))
            .join(EmpresaDB, ControleMensalDB.empresa_id == EmpresaDB.id)
            .filter(EmpresaDB.contabilidade_id == contabilidade_id)
            .filter(ControleMensalDB.ano == ano)
            .filter(ControleMensalDB.mes == mes)
        )
        
        controles_raw = controles_query.all()
        
        # Build detailed control objects
        controles = []
        for controle_db, nome_empresa in controles_raw:
            # Get tasks for this control
            tarefas_raw = (
                db.query(TarefaControleDB)
                .filter(TarefaControleDB.controle_mensal_id == controle_db.id)
                .all()
            )
            
            tarefas = [
                Tarefa(
                    id=tarefa.id,
                    nome_tarefa=tarefa.descricao_tarefa,
                    concluido=tarefa.concluida,
                    data_conclusao=tarefa.data_conclusao
                ) for tarefa in tarefas_raw
            ]
            
            controles.append(
                ControleMensalDetalhado(
                    id_controle=controle_db.id,
                    mes=controle_db.mes,
                    ano=controle_db.ano,
                    status_dados=controle_db.status,
                    id_empresa=controle_db.empresa_id,
                    nome_empresa=nome_empresa,
                    tarefas=tarefas
                )
            )
        
        # Calculate summary statistics
        total_empresas = (
            db.query(EmpresaDB)
            .filter(EmpresaDB.contabilidade_id == contabilidade_id)
            .count()
        )
        
        controles_iniciados = len(controles)
        controles_concluidos = sum(1 for c in controles if c.status_dados == "CONCLUﾃ好O")
        percentual_conclusao = (
            f"{(controles_concluidos / controles_iniciados * 100):.2f}%" 
            if controles_iniciados > 0 else "0.00%"
        )
        
        sumario = ControleMensalSumario(
            total_empresas=total_empresas,
            controles_iniciados=controles_iniciados,
            controles_concluidos=controles_concluidos,
            percentual_conclusao=percentual_conclusao
        )
        
        response = ControleMensalResponse(
            sumario=sumario,
            controles=controles
        )
        
        logger.info(f"Retrieved {len(controles)} controles for {ano}/{mes} - {percentual_conclusao} completed")
        return response

    except Exception as e:
        logger.error(f"Failed to get controles for {ano}/{mes}: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao buscar controles: {str(e)}"
        )


@app.patch("/v1/controles-mensais/tarefas/{tarefa_id}/status", response_model=Tarefa, tags=["controle-mensal"])
def atualizar_status_tarefa(
    tarefa_id: int, concluido: bool, db: Session = Depends(get_db)
):
    """
    Atualizar o status de conclusﾃ｣o de uma tarefa
    """
    tarefa = db.query(TarefaControleDB).filter(TarefaControleDB.id == tarefa_id).first()
    
    if not tarefa:
        raise HTTPException(status_code=404, detail="Tarefa nﾃ｣o encontrada")
    
    try:
        tarefa.concluida = concluido
        tarefa.data_conclusao = datetime.now(timezone.utc) if concluido else None
        
        db.commit()
        db.refresh(tarefa)
        
        logger.info(f"Task {tarefa_id} updated: concluido={concluido}")
        
        return Tarefa(
            id=tarefa.id,
            nome_tarefa=tarefa.descricao_tarefa, 
            concluido=tarefa.concluida,
            data_conclusao=tarefa.data_conclusao
        )

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to update task {tarefa_id}: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao atualizar tarefa: {str(e)}"
        )


# ===== TEMPLATE ENDPOINTS =====

@app.get("/v1/templates", response_model=List[TemplateControle], tags=["templates"])
def listar_templates(db: Session = Depends(get_db)):
    """
    Listar todos os templates da contabilidade do usuﾃ｡rio
    """
    try:
        # TODO: Get contabilidade_id from auth context
        contabilidade_id = 1
        
        templates_raw = (
            db.query(TemplateControleDB)
            .filter(TemplateControleDB.contabilidade_id == contabilidade_id)
            .all()
        )
        
        templates = []
        for template_db in templates_raw:
            # Get tasks for this template
            tarefas_raw = (
                db.query(TemplateControleTarefaDB.descricao_tarefa)
                .filter(TemplateControleTarefaDB.template_id == template_db.id)
                .all()
            )
            
            tarefas = [t[0] for t in tarefas_raw]
            
            templates.append(
                TemplateControle(
                    id=template_db.id,
                    contabilidade_id=template_db.contabilidade_id,
                    nome_template=template_db.nome_template,
                    descricao=template_db.descricao,
                    criado_em=template_db.criado_em,
                    tarefas=tarefas
                )
            )
        
        return templates

    except Exception as e:
        logger.error(f"Failed to list templates: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao listar templates: {str(e)}"
        )


@app.post("/v1/templates", response_model=TemplateControle, tags=["templates"])
def criar_template(template: TemplateControleCreate, db: Session = Depends(get_db)):
    """
    Criar um novo template de controle
    """
    try:
        # TODO: Get contabilidade_id from auth context
        contabilidade_id = 1
        
        # Create template
        template_db = TemplateControleDB(
            contabilidade_id=contabilidade_id,
            nome_template=template.nome_template,
            descricao=template.descricao,
            criado_em=datetime.now(timezone.utc)
        )
        
        db.add(template_db)
        db.flush()  # Get the ID without committing
        
        # Create template tasks
        for descricao in template.tarefas:
            tarefa_db = TemplateControleTarefaDB(
                template_id=template_db.id,
                descricao_tarefa=descricao
            )
            db.add(tarefa_db)
        
        db.commit()
        db.refresh(template_db)
        
        logger.info(f"Created template: {template_db.id} - {template_db.nome_template}")
        
        return TemplateControle(
            id=template_db.id,
            contabilidade_id=template_db.contabilidade_id,
            nome_template=template_db.nome_template,
            descricao=template_db.descricao,
            criado_em=template_db.criado_em,
            tarefas=template.tarefas
        )

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to create template: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao criar template: {str(e)}"
        )


@app.post("/v1/controles/aplicar-template", tags=["templates"])
def aplicar_template(aplicacao: TemplateAplicacao, db: Session = Depends(get_db)):
    """
    Aplicar um template a empresas para criar controles mensais
    """
    try:
        # TODO: Get contabilidade_id from auth context  
        contabilidade_id = 1
        
        # Verify template exists and belongs to the accounting firm
        template = (
            db.query(TemplateControleDB)
            .filter(TemplateControleDB.id == aplicacao.template_id)
            .filter(TemplateControleDB.contabilidade_id == contabilidade_id)
            .first()
        )
        
        if not template:
            raise HTTPException(status_code=404, detail="Template nﾃ｣o encontrado")
        
        # Get template tasks
        template_tarefas = (
            db.query(TemplateControleTarefaDB)
            .filter(TemplateControleTarefaDB.template_id == template.id)
            .all()
        )
        
        # Get companies to apply to
        empresas_query = db.query(EmpresaDB).filter(EmpresaDB.contabilidade_id == contabilidade_id)
        
        if aplicacao.empresas_ids:
            empresas_query = empresas_query.filter(EmpresaDB.id.in_(aplicacao.empresas_ids))
        
        empresas = empresas_query.all()
        
        controles_criados = 0
        tarefas_criadas = 0
        
        for empresa in empresas:
            # Check if control already exists for this month/year
            controle_existente = (
                db.query(ControleMensalDB)
                .filter(ControleMensalDB.empresa_id == empresa.id)
                .filter(ControleMensalDB.mes == aplicacao.mes)
                .filter(ControleMensalDB.ano == aplicacao.ano)
                .first()
            )
            
            if controle_existente:
                continue  # Skip if already exists
            
            # Create monthly control
            controle = ControleMensalDB(
                empresa_id=empresa.id,
                mes=aplicacao.mes,
                ano=aplicacao.ano,
                status="AGUARD. DADOS",
                criado_em=datetime.now(timezone.utc)
            )
            
            db.add(controle)
            db.flush()  # Get ID
            controles_criados += 1
            
            # Create tasks from template
            for template_tarefa in template_tarefas:
                tarefa = TarefaControleDB(
                    controle_mensal_id=controle.id,
                    descricao_tarefa=template_tarefa.descricao_tarefa,
                    concluida=False,
                    criado_em=datetime.now(timezone.utc)
                )
                db.add(tarefa)
                tarefas_criadas += 1
        
        db.commit()
        
        logger.info(f"Applied template {aplicacao.template_id}: {controles_criados} controles, {tarefas_criadas} tarefas created")
        
        return {
            "message": f"Template aplicado com sucesso: {controles_criados} controles criados com {tarefas_criadas} tarefas",
            "controles_criados": controles_criados,
            "tarefas_criadas": tarefas_criadas
        }

    except Exception as e:
        db.rollback()
        logger.error(f"Failed to apply template {aplicacao.template_id}: {e}")
        raise HTTPException(
            status_code=500, detail=f"Erro ao aplicar template: {str(e)}"
        )


# ===== PAYROLL AUDIT ENDPOINTS =====

@app.post("/v1/folha/auditar", response_model=ProcessamentoFolhaResponse, tags=["folha-pagamento"])
async def auditar_folha_pagamento(
    empresa_id: int,
    mes: int,
    ano: int,
    arquivo_pdf: UploadFile = File(...),
    db: Session = Depends(get_db)
):
    """
    Motor de Auditoria Inteligente da Folha de Pagamento
    
    Processa PDFs da folha de pagamento usando IA para extrair dados,
    audita contra CCTs e gera relatﾃｳrio de conformidade e divergﾃｪncias.
    """
    try:
        # Validate request parameters
        if mes < 1 or mes > 12:
            raise HTTPException(status_code=400, detail="Mﾃｪs deve estar entre 1 e 12")
        if ano < 2020 or ano > 2030:
            raise HTTPException(status_code=400, detail="Ano deve estar entre 2020 e 2030")
        
        # Validate file
        if not arquivo_pdf.filename.lower().endswith('.pdf'):
            raise HTTPException(status_code=400, detail="Apenas arquivos PDF sﾃ｣o aceitos")
        
        # Verify company exists
        empresa = db.query(EmpresaDB).filter(EmpresaDB.id == empresa_id).first()
        if not empresa:
            raise HTTPException(status_code=404, detail="Empresa nﾃ｣o encontrada")
        
        # Check if processing already exists for this month/year
        processamento_existente = (
            db.query(ProcessamentosFolhaDB)
            .filter(ProcessamentosFolhaDB.empresa_id == empresa_id)
            .filter(ProcessamentosFolhaDB.mes == mes)
            .filter(ProcessamentosFolhaDB.ano == ano)
            .first()
        )
        
        if processamento_existente:
            raise HTTPException(
                status_code=409, 
                detail=f"Jﾃ｡ existe processamento para {empresa.nome} em {mes:02d}/{ano}"
            )
        
        # Read PDF content
        pdf_content = await arquivo_pdf.read()
        
        # Create processing record
        processamento = ProcessamentosFolhaDB(
            empresa_id=empresa_id,
            mes=mes,
            ano=ano,
            arquivo_pdf=arquivo_pdf.filename,
            status_processamento="PROCESSANDO",
            criado_em=datetime.now(timezone.utc)
        )
        
        db.add(processamento)
        db.flush()  # Get the ID
        
        # TODO: Implement AI processing (for now, simulate with mock data)
        dados_extraidos, divergencias = await processar_pdf_com_ia(
            pdf_content, empresa, mes, ano, db
        )
        
        # Update processing record with results
        processamento.dados_extraidos = json.dumps(dados_extraidos, ensure_ascii=False)
        processamento.relatorio_divergencias = json.dumps(divergencias, ensure_ascii=False)
        processamento.total_funcionarios = len(dados_extraidos.get("funcionarios", []))
        processamento.total_divergencias = len(divergencias)
        processamento.status_processamento = "CONCLUIDO"
        processamento.concluido_em = datetime.now(timezone.utc)
        
        db.commit()
        db.refresh(processamento)
        
        logger.info(
            f"Payroll audit completed: empresa_id={empresa_id}, "
            f"funcionarios={processamento.total_funcionarios}, "
            f"divergencias={processamento.total_divergencias}"
        )
        
        # Convert divergencias to Pydantic models
        divergencias_models = [
            FuncionarioDivergencia(
                nome_funcionario=div["nome_funcionario"],
                tipo_divergencia=div["tipo_divergencia"],
                descricao_divergencia=div["descricao_divergencia"],
                valor_encontrado=div.get("valor_encontrado"),
                valor_esperado=div.get("valor_esperado"),
                campo_afetado=div["campo_afetado"]
            ) for div in divergencias
        ]
        
        return ProcessamentoFolhaResponse(
            id=processamento.id,
            empresa_id=processamento.empresa_id,
            mes=processamento.mes,
            ano=processamento.ano,
            arquivo_pdf=processamento.arquivo_pdf,
            total_funcionarios=processamento.total_funcionarios,
            total_divergencias=processamento.total_divergencias,
            status_processamento=processamento.status_processamento,
            criado_em=processamento.criado_em,
            concluido_em=processamento.concluido_em,
            divergencias=divergencias_models
        )

    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Failed to process payroll audit: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erro no processamento da auditoria: {str(e)}"
        )


@app.get("/v1/folha/processamentos/{empresa_id}", response_model=List[ProcessamentoFolhaResponse], tags=["folha-pagamento"])
def listar_processamentos_folha(
    empresa_id: int, 
    db: Session = Depends(get_db)
):
    """
    Listar histﾃｳrico de processamentos de folha de pagamento de uma empresa
    """
    try:
        # Verify company exists
        empresa = db.query(EmpresaDB).filter(EmpresaDB.id == empresa_id).first()
        if not empresa:
            raise HTTPException(status_code=404, detail="Empresa nﾃ｣o encontrada")
        
        processamentos = (
            db.query(ProcessamentosFolhaDB)
            .filter(ProcessamentosFolhaDB.empresa_id == empresa_id)
            .order_by(desc(ProcessamentosFolhaDB.criado_em))
            .all()
        )
        
        result = []
        for proc in processamentos:
            # Parse divergencias from JSON
            divergencias_json = json.loads(proc.relatorio_divergencias or "[]")
            divergencias_models = [
                FuncionarioDivergencia(
                    nome_funcionario=div["nome_funcionario"],
                    tipo_divergencia=div["tipo_divergencia"],
                    descricao_divergencia=div["descricao_divergencia"],
                    valor_encontrado=div.get("valor_encontrado"),
                    valor_esperado=div.get("valor_esperado"),
                    campo_afetado=div["campo_afetado"]
                ) for div in divergencias_json
            ]
            
            result.append(ProcessamentoFolhaResponse(
                id=proc.id,
                empresa_id=proc.empresa_id,
                mes=proc.mes,
                ano=proc.ano,
                arquivo_pdf=proc.arquivo_pdf,
                total_funcionarios=proc.total_funcionarios,
                total_divergencias=proc.total_divergencias,
                status_processamento=proc.status_processamento,
                criado_em=proc.criado_em,
                concluido_em=proc.concluido_em,
                divergencias=divergencias_models
            ))
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to list payroll processings: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao listar processamentos: {str(e)}"
        )


async def processar_pdf_com_ia(pdf_content: bytes, empresa: EmpresaDB, mes: int, ano: int, db: Session):
    """
    AI-powered PDF processing and auditing logic
    
    This is where the real magic happens:
    1. Extract data from PDF using OCR/Document AI
    2. Structure the data (employees, earnings, deductions)
    3. Load applicable CCT rules for the company
    4. Audit each employee's data against the rules
    5. Generate divergence reports
    
    For now, this returns mock data to demonstrate the functionality.
    """
    import asyncio
    
    # Simulate AI processing time
    await asyncio.sleep(0.5)
    
    # Mock extracted data (in production this would come from AI/OCR)
    dados_extraidos = {
        "arquivo_processado": f"folha_{mes:02d}_{ano}.pdf",
        "data_processamento": datetime.now(timezone.utc).isoformat(),
        "funcionarios": [
            {
                "nome": "Joﾃ｣o Silva",
                "cargo": "Vendedor",
                "salario_base": 1800.00,
                "horas_extras": {"50%": 120.00, "100%": 0.00},
                "descontos": {"INSS": 198.00, "IRRF": 0.00},
                "liquido": 1722.00
            },
            {
                "nome": "Maria Oliveira", 
                "cargo": "Gerente",
                "salario_base": 3500.00,
                "horas_extras": {"50%": 250.00, "100%": 100.00},
                "descontos": {"INSS": 445.50, "IRRF": 180.25},
                "liquido": 3224.25
            },
            {
                "nome": "Carlos Santos",
                "cargo": "Vendedor",
                "salario_base": 1850.00,
                "horas_extras": {"50%": 0.00, "100%": 0.00},
                "descontos": {"INSS": 203.50, "IRRF": 0.00},
                "liquido": 1646.50
            }
        ]
    }
    
    # Mock CCT rules (in production this would come from database)
    regras_cct = {
        "piso_salarial": 1850.00,
        "percentual_he_50": 60.0,  # 60% instead of 50%
        "percentual_he_100": 100.0,
        "auxilio_creche": 150.00,
        "vale_transporte": 6.0  # 6% do salﾃ｡rio base
    }
    
    # Mock audit logic - compare extracted data against CCT rules
    divergencias = []
    
    for funcionario in dados_extraidos["funcionarios"]:
        nome = funcionario["nome"]
        
        # Check minimum wage
        if funcionario["salario_base"] < regras_cct["piso_salarial"]:
            divergencias.append({
                "nome_funcionario": nome,
                "tipo_divergencia": "ALERTA",
                "descricao_divergencia": f"Salﾃ｡rio base (R$ {funcionario['salario_base']:,.2f}) estﾃ｡ abaixo do piso da CCT",
                "valor_encontrado": f"R$ {funcionario['salario_base']:,.2f}",
                "valor_esperado": f"R$ {regras_cct['piso_salarial']:,.2f}",
                "campo_afetado": "salario_base"
            })
        
        # Check overtime calculation (mock - just for Joﾃ｣o Silva)
        if nome == "Joﾃ｣o Silva" and funcionario["horas_extras"]["50%"] > 0:
            divergencias.append({
                "nome_funcionario": nome,
                "tipo_divergencia": "AVISO",
                "descricao_divergencia": "Valor da hora extra (50%) pode nﾃ｣o corresponder ao valor da CCT (60%)",
                "valor_encontrado": f"R$ {funcionario['horas_extras']['50%']:,.2f}",
                "valor_esperado": "Verificar cﾃ｡lculo com 60%",
                "campo_afetado": "horas_extras_50"
            })
        
        # Check missing benefits (mock - for all employees)
        if nome != "Carlos Santos":  # Simulate Carlos has it, others don't
            divergencias.append({
                "nome_funcionario": nome,
                "tipo_divergencia": "INFO",
                "descricao_divergencia": f"Benefﾃｭcio 'Auxﾃｭlio Creche' previsto na CCT nﾃ｣o foi encontrado na folha",
                "valor_encontrado": None,
                "valor_esperado": f"R$ {regras_cct['auxilio_creche']:,.2f}",
                "campo_afetado": "auxilio_creche"
            })
    
    return dados_extraidos, divergencias


# ===== RISK ANALYSIS ENDPOINTS =====

@app.post("/v1/riscos/analisar", response_model=AnaliseRiscoResponse, tags=["riscos"])
async def analisar_riscos_empresa(
    request: AnaliseRiscoRequest,
    db: Session = Depends(get_db)
):
    """
    沐ｮ CONSULTOR DE RISCOS - Anﾃ｡lise Preditiva Completa
    
    Motor de anﾃ｡lise que atua como um "orﾃ｡culo estratﾃｩgico":
    1. Agrega dados histﾃｳricos da empresa (12-24 meses)
    2. Executa anﾃ｡lise de conformidade trabalhista, fiscal e operacional
    3. Aplica algoritmos de detecﾃｧﾃ｣o de padrﾃｵes e anomalias
    4. Gera score de risco (0-100) e recomendaﾃｧﾃｵes especﾃｭficas
    5. Armazena histﾃｳrico para anﾃ｡lise de evoluﾃｧﾃ｣o temporal
    
    Esta funcionalidade transforma contabilidade reativa em consultoria proativa.
    """
    try:
        # Verify company exists and get details
        empresa = db.query(EmpresaDB).filter(EmpresaDB.id == request.empresa_id).first()
        if not empresa:
            raise HTTPException(status_code=404, detail="Empresa nﾃ｣o encontrada")
        
        contabilidade = db.query(ContabilidadeDB).filter(ContabilidadeDB.id == empresa.contabilidade_id).first()
        
        logger.info(f"沐 Starting risk analysis for company: {empresa.nome} (ID: {request.empresa_id})")
        
        # Execute comprehensive risk analysis
        resultado_analise = await executar_analise_completa_riscos(
            empresa=empresa, 
            contabilidade=contabilidade,
            db=db
        )
        
        # Get previous analysis for comparison
        analise_anterior = (
            db.query(HistoricoAnalisesRiscoDB)
            .filter(HistoricoAnalisesRiscoDB.empresa_id == request.empresa_id)
            .order_by(desc(HistoricoAnalisesRiscoDB.analisado_em))
            .first()
        )
        
        score_anterior = analise_anterior.score_risco if analise_anterior else None
        variacao_score = (resultado_analise["score_risco"] - score_anterior) if score_anterior else None
        
        # Store analysis in history
        nova_analise = HistoricoAnalisesRiscoDB(
            empresa_id=request.empresa_id,
            contabilidade_id=empresa.contabilidade_id,
            score_risco=resultado_analise["score_risco"],
            relatorio_completo=json.dumps(resultado_analise["relatorio_completo"], ensure_ascii=False),
            analisado_em=datetime.now(timezone.utc),
            analisado_por_user_id="sistema"  # TODO: Get from auth context
        )
        
        db.add(nova_analise)
        db.commit()
        db.refresh(nova_analise)
        
        # Build response
        response = AnaliseRiscoResponse(
            empresa_id=request.empresa_id,
            empresa_nome=empresa.nome,
            score_risco=resultado_analise["score_risco"],
            nivel_risco=resultado_analise["nivel_risco"],
            data_analise=datetime.now(timezone.utc),
            progresso_analise=resultado_analise["progresso_analise"],
            riscos_encontrados=resultado_analise["riscos_encontrados"],
            total_riscos=resultado_analise["total_riscos"],
            riscos_criticos=resultado_analise["riscos_criticos"],
            riscos_altos=resultado_analise["riscos_altos"],
            riscos_medios=resultado_analise["riscos_medios"],
            riscos_baixos=resultado_analise["riscos_baixos"],
            score_anterior=score_anterior,
            variacao_score=variacao_score
        )
        
        logger.info(
            f"笨 Risk analysis completed for {empresa.nome}: "
            f"Score={resultado_analise['score_risco']}/100, "
            f"Level={resultado_analise['nivel_risco']}, "
            f"Total Risks={resultado_analise['total_riscos']}"
        )
        
        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to analyze risks for empresa_id {request.empresa_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro na anﾃ｡lise de riscos: {str(e)}"
        )


@app.get("/v1/riscos/historico/{empresa_id}", response_model=List[HistoricoAnaliseRisco], tags=["riscos"])
def obter_historico_riscos(
    empresa_id: int,
    limit: int = Query(10, ge=1, le=50, description="Nﾃｺmero mﾃ｡ximo de anﾃ｡lises"),
    db: Session = Depends(get_db)
):
    """
    沒 Histﾃｳrico de Anﾃ｡lises de Risco
    
    Recupera o histﾃｳrico de anﾃ｡lises de risco de uma empresa para:
    - Acompanhar evoluﾃｧﾃ｣o do score de risco
    - Identificar tendﾃｪncias
    - Avaliar efetividade das aﾃｧﾃｵes implementadas
    """
    try:
        # Verify company exists
        empresa = db.query(EmpresaDB).filter(EmpresaDB.id == empresa_id).first()
        if not empresa:
            raise HTTPException(status_code=404, detail="Empresa nﾃ｣o encontrada")
        
        # Get historical analyses
        historico = (
            db.query(HistoricoAnalisesRiscoDB)
            .filter(HistoricoAnalisesRiscoDB.empresa_id == empresa_id)
            .order_by(desc(HistoricoAnalisesRiscoDB.analisado_em))
            .limit(limit)
            .all()
        )
        
        result = []
        for analise in historico:
            try:
                relatorio_resumo = json.loads(analise.relatorio_completo or "{}")
            except (json.JSONDecodeError, TypeError):
                relatorio_resumo = {}
            
            result.append(HistoricoAnaliseRisco(
                id=analise.id,
                empresa_id=analise.empresa_id,
                contabilidade_id=analise.contabilidade_id,
                score_risco=analise.score_risco,
                data_analise=analise.analisado_em,
                relatorio_resumo={
                    "total_riscos": relatorio_resumo.get("total_riscos", 0),
                    "nivel_risco": relatorio_resumo.get("nivel_risco", "DESCONHECIDO"),
                    "categorias": relatorio_resumo.get("categorias_resumo", {})
                }
            ))
        
        logger.info(f"Retrieved {len(result)} historical risk analyses for empresa_id {empresa_id}")
        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get risk history for empresa_id {empresa_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao obter histﾃｳrico de riscos: {str(e)}"
        )


async def executar_analise_completa_riscos(
    empresa: EmpresaDB, 
    contabilidade: ContabilidadeDB,
    db: Session
) -> dict:
    """
    洫 CORE DA ANﾃ´ISE DE RISCOS
    
    Esta funﾃｧﾃ｣o implementa o "cﾃｩrebro" do Consultor de Riscos:
    1. Agregaﾃｧﾃ｣o massiva de dados histﾃｳricos
    2. Motor de regras de conformidade
    3. Anﾃ｡lise de padrﾃｵes e anomalias
    4. Quantificaﾃｧﾃ｣o e classificaﾃｧﾃ｣o de riscos
    5. Geraﾃｧﾃ｣o de recomendaﾃｧﾃｵes especﾃｭficas
    
    Simula processos que na produﾃｧﾃ｣o usariam:
    - Anﾃ｡lise de dados dos ﾃｺltimos 12-24 meses
    - Consulta a bases de CCTs e legislaﾃｧﾃ｣o
    - Algoritmos de ML para detecﾃｧﾃ｣o de anomalias
    - Sistema especialista para recomendaﾃｧﾃｵes
    """
    import asyncio
    from datetime import datetime, timedelta, timezone
    
    # Simulate analysis progress
    progresso_analise = {}
    
    # Step 1: Data Aggregation (simulate time-consuming process)
    progresso_analise["coleta_dados"] = "CONCLUﾃ好O"
    await asyncio.sleep(0.2)
    
    # Get historical data (last 12 months)
    data_limite = datetime.now(timezone.utc) - timedelta(days=365)
    
    controles_historicos = (
        db.query(ControleMensalDB)
        .filter(ControleMensalDB.empresa_id == empresa.id)
        .filter(ControleMensalDB.criado_em >= data_limite)
        .count()
    )
    
    processamentos_folha = (
        db.query(ProcessamentosFolhaDB)
        .filter(ProcessamentosFolhaDB.empresa_id == empresa.id)
        .filter(ProcessamentosFolhaDB.criado_em >= data_limite)
        .count()
    )
    
    progresso_analise["analise_conformidade_trabalhista"] = "CONCLUﾃ好O"
    await asyncio.sleep(0.2)
    
    progresso_analise["analise_conformidade_fiscal"] = "CONCLUﾃ好O"
    await asyncio.sleep(0.2)
    
    progresso_analise["deteccao_anomalias"] = "CONCLUﾃ好O"  
    await asyncio.sleep(0.2)
    
    progresso_analise["calculo_score"] = "CONCLUﾃ好O"
    await asyncio.sleep(0.1)
    
    # Risk Analysis Engine - Simulation with realistic business logic
    riscos_encontrados = []
    
    # 1. TRABALHISTA RISKS
    if controles_historicos < 6:  # Less than 6 months of controls
        riscos_encontrados.append(RiscoDetalhado(
            categoria="TRABALHISTA",
            tipo_risco="Histﾃｳrico de Controles Insuficiente",
            descricao="Empresa possui poucos controles mensais registrados no sistema",
            evidencia=f"Apenas {controles_historicos} controles encontrados nos ﾃｺltimos 12 meses",
            impacto_potencial="Risco de nﾃ｣o conformidade com obrigaﾃｧﾃｵes trabalhistas. Possﾃｭvel multa de R$ 2.000 a R$ 20.000 por irregularidade nﾃ｣o detectada.",
            plano_acao="1. Implementar controles mensais sistemﾃ｡ticos. 2. Revisar processos de documentaﾃｧﾃ｣o. 3. Treinar equipe em boas prﾃ｡ticas.",
            severidade=4  # High severity
        ))
    
    # Simulate payroll compliance check
    if processamentos_folha == 0:
        riscos_encontrados.append(RiscoDetalhado(
            categoria="TRABALHISTA", 
            tipo_risco="Auditoria de Folha Pendente",
            descricao="Nenhuma auditoria de folha foi realizada recentemente",
            evidencia="Sistema nﾃ｣o registra processamentos de auditoria da folha nos ﾃｺltimos 12 meses",
            impacto_potencial="Riscos nﾃ｣o identificados em cﾃ｡lculos trabalhistas. Estimativa de exposiﾃｧﾃ｣o: R$ 5.000 a R$ 50.000 em possﾃｭveis correﾃｧﾃｵes.",
            plano_acao="1. Realizar auditoria completa da folha de pagamento. 2. Implementar auditorias mensais automﾃ｡ticas. 3. Validar cﾃ｡lculos contra CCT vigente.",
            severidade=3  # Medium-high severity
        ))
    
    # 2. FISCAL RISKS  
    # Simulate tax compliance analysis with safe datetime handling
    empresa_criada = getattr(empresa, 'criado_em', None)
    if empresa_criada is None:
        # Fallback: assume company created 400 days ago if no creation date
        dias_funcionamento = 400
    else:
        # Make sure both datetimes have timezone info
        now = datetime.now(timezone.utc)
        if empresa_criada.tzinfo is None:
            # If empresa_criada is timezone-naive, assume it's UTC
            empresa_criada = empresa_criada.replace(tzinfo=timezone.utc)
        dias_funcionamento = (now - empresa_criada).days
    
    if dias_funcionamento > 365 and controles_historicos < 12:
        riscos_encontrados.append(RiscoDetalhado(
            categoria="FISCAL",
            tipo_risco="Controle Fiscal Inconsistente", 
            descricao="Empresa com mais de 1 ano de funcionamento apresenta gaps no controle mensal",
            evidencia=f"Empresa ativa hﾃ｡ {dias_funcionamento} dias mas apenas {controles_historicos} controles registrados",
            impacto_potencial="Risco de autuaﾃｧﾃ｣o fiscal por falta de documentaﾃｧﾃ｣o. Multas podem variar de 20% a 75% do tributo devido.",
            plano_acao="1. Regularizar controles em atraso. 2. Implementar rotina de compliance fiscal mensal. 3. Revisar regime tributﾃ｡rio.",
            severidade=5  # Critical severity
        ))
    
    # 3. OPERATIONAL RISKS
    # Simulate operational efficiency analysis
    if controles_historicos > 0 and controles_historicos < 8:
        riscos_encontrados.append(RiscoDetalhado(
            categoria="OPERACIONAL",
            tipo_risco="Eficiﾃｪncia Operacional Subﾃｳtima",
            descricao="Padrﾃ｣o irregular nos controles mensais indica possﾃｭveis problemas operacionais",
            evidencia=f"Variaﾃｧﾃ｣o significativa na frequﾃｪncia de controles: {controles_historicos} em 12 meses",
            impacto_potencial="Ineficiﾃｪncia operacional pode resultar em aumento de 15-30% nos custos de compliance.",
            plano_acao="1. Padronizar processos operacionais. 2. Implementar automaﾃｧﾃｵes. 3. Treinar equipe em ferramentas do sistema.",
            severidade=2  # Low-medium severity
        ))
    
    # Add some positive findings for companies with good practices
    if controles_historicos >= 10 and processamentos_folha > 0:
        riscos_encontrados.append(RiscoDetalhado(
            categoria="CONFORMIDADE",
            tipo_risco="Prﾃ｡ticas de Compliance Adequadas",
            descricao="Empresa demonstra boas prﾃ｡ticas de controle e auditoria",
            evidencia=f"Registros regulares: {controles_historicos} controles e {processamentos_folha} auditorias de folha",
            impacto_potencial="Reduﾃｧﾃ｣o significativa do risco de nﾃ｣o conformidade. Potencial economia de 40-60% em multas evitadas.",
            plano_acao="1. Manter rotina estabelecida. 2. Considerar automaﾃｧﾃｵes adicionais. 3. Usar como benchmark para outras empresas.",
            severidade=1  # Low risk (positive finding)
        ))
    
    # Calculate risk score based on found risks
    total_riscos = len(riscos_encontrados)
    riscos_criticos = sum(1 for r in riscos_encontrados if r.severidade == 5)
    riscos_altos = sum(1 for r in riscos_encontrados if r.severidade == 4) 
    riscos_medios = sum(1 for r in riscos_encontrados if r.severidade == 3)
    riscos_baixos = sum(1 for r in riscos_encontrados if r.severidade <= 2)
    
    # Scoring algorithm: Base score starts at 100 (perfect), subtract points for risks
    score_risco = 100
    score_risco -= (riscos_criticos * 25)  # Critical risks: -25 points each
    score_risco -= (riscos_altos * 15)     # High risks: -15 points each  
    score_risco -= (riscos_medios * 10)    # Medium risks: -10 points each
    score_risco -= (riscos_baixos * 5)     # Low risks: -5 points each (but positive findings add back)
    
    # Add bonus points for positive compliance findings
    bonus_compliance = sum(5 for r in riscos_encontrados if r.categoria == "CONFORMIDADE")
    score_risco = min(100, max(0, score_risco + bonus_compliance))  # Keep between 0-100
    
    # Determine risk level based on score
    if score_risco >= 80:
        nivel_risco = "BAIXO"
    elif score_risco >= 60:
        nivel_risco = "Mﾃ吋IO" 
    elif score_risco >= 40:
        nivel_risco = "ALTO"
    else:
        nivel_risco = "CRﾃ控ICO"
    
    # Build comprehensive report
    relatorio_completo = {
        "analise_id": f"RISK_{empresa.id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "empresa_dados": {
            "id": empresa.id,
            "nome": empresa.nome,
            "contabilidade_id": empresa.contabilidade_id,
            "dias_funcionamento": dias_funcionamento
        },
        "dados_historicos": {
            "controles_mensais_12m": controles_historicos,
            "auditorias_folha_12m": processamentos_folha,
            "periodo_analise": "12 meses"
        },
        "score_risco": score_risco,
        "nivel_risco": nivel_risco,
        "total_riscos": total_riscos,
        "riscos_criticos": riscos_criticos,
        "riscos_altos": riscos_altos,
        "riscos_medios": riscos_medios,
        "riscos_baixos": riscos_baixos,
        "categorias_resumo": {
            "TRABALHISTA": sum(1 for r in riscos_encontrados if r.categoria == "TRABALHISTA"),
            "FISCAL": sum(1 for r in riscos_encontrados if r.categoria == "FISCAL"),
            "OPERACIONAL": sum(1 for r in riscos_encontrados if r.categoria == "OPERACIONAL"),
            "CONFORMIDADE": sum(1 for r in riscos_encontrados if r.categoria == "CONFORMIDADE")
        },
        "algoritmo_versao": "v1.0",
        "processado_em": datetime.now(timezone.utc).isoformat()
    }
    
    return {
        "score_risco": score_risco,
        "nivel_risco": nivel_risco,
        "progresso_analise": progresso_analise,
        "riscos_encontrados": riscos_encontrados,
        "total_riscos": total_riscos,
        "riscos_criticos": riscos_criticos,
        "riscos_altos": riscos_altos,
        "riscos_medios": riscos_medios,
        "riscos_baixos": riscos_baixos,
        "relatorio_completo": relatorio_completo
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8001)
