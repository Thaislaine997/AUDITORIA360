"""
Performance Test Suite for AUDITORIA360 Optimized Endpoints (Refatorado)
Tests the performance improvements implemented for the three critical endpoints
Uses modularized performance testing framework for better organization.
"""

import sys
import os
from pathlib import Path

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from src.utils.performance_testing import PerformanceTestOrchestrator
    from src.utils.error_handling import (
        error_handler, ErrorCategory, ErrorSeverity, handle_exceptions, safe_execute
    )
    import logging
    
    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    @handle_exceptions(ErrorCategory.PERFORMANCE, ErrorSeverity.HIGH)
    def run_performance_test_suite() -> dict:
        """
        Executa suite completa de testes de performance usando sistema modularizado.
        
        Returns:
            dict: Resultado consolidado dos testes
        """
        try:
            # Criar orquestrador de testes
            orchestrator = PerformanceTestOrchestrator()
            
            # Executar todos os testes
            results = orchestrator.run_all_performance_tests()
            
            logger.info("Suite de testes de performance executada com sucesso")
            return results
            
        except Exception as e:
            error = error_handler.create_error(
                message="Falha durante execu√ß√£o dos testes de performance",
                category=ErrorCategory.PERFORMANCE,
                severity=ErrorSeverity.HIGH,
                details="Erro durante execu√ß√£o da suite de testes",
                original_exception=e
            )
            error_handler.handle_error(error)
            raise

    def save_performance_report(results: dict, output_file: str = "performance_test_report.json") -> None:
        """
        Salva relat√≥rio de performance em arquivo.
        
        Args:
            results: Resultados dos testes
            output_file: Nome do arquivo de sa√≠da
        """
        def _save_report():
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, default=str)
            print(f"\nüìÑ Relat√≥rio detalhado salvo em: {output_file}")
            return True
        
        success = safe_execute(
            _save_report,
            default_value=False,
            category=ErrorCategory.SYSTEM
        )
        
        if not success:
            print(f"‚ùå Falha ao salvar relat√≥rio em {output_file}")

    def display_performance_summary(results: dict) -> None:
        """
        Exibe resumo dos resultados de performance.
        
        Args:
            results: Resultados dos testes
        """
        print("\nüìä RESUMO EXECUTIVO DOS TESTES")
        print("=" * 40)
        
        # M√©tricas gerais
        total_suites = results.get('total_test_suites', 0)
        suites_passed = results.get('suites_passed', 0)
        success_rate = results.get('overall_success_rate', 0)
        
        print(f"Total de Suites: {total_suites}")
        print(f"Suites Aprovadas: {suites_passed}")
        print(f"Taxa de Sucesso: {success_rate:.1f}%")
        
        # Status geral
        status = results.get('overall_status', 'unknown')
        status_icon = {
            'success': '‚úÖ',
            'needs_improvement': '‚ö†Ô∏è',
            'error': '‚ùå'
        }.get(status, '‚ùì')
        
        print(f"Status Geral: {status_icon} {status.replace('_', ' ').title()}")
        
        # Recomenda√ß√µes
        if status != 'success':
            print("\nüí° Recomenda√ß√µes:")
            print("   ‚Ä¢ Revisar endpoints com performance abaixo da meta")
            print("   ‚Ä¢ Considerar otimiza√ß√µes adicionais de cache")
            print("   ‚Ä¢ Analisar queries de banco de dados")
            print("   ‚Ä¢ Implementar mais paraleliza√ß√£o")

    def main():
        """
        Fun√ß√£o principal dos testes de performance usando sistema modularizado.
        """
        try:
            print("üöÄ AUDITORIA360 - Suite de Testes de Performance Refatorada")
            print("Sistema de testes modularizado e otimizado")
            print()
            
            # Executar testes
            test_results = run_performance_test_suite()
            
            # Exibir resumo
            display_performance_summary(test_results)
            
            # Salvar relat√≥rio
            save_performance_report(test_results)
            
            # Determinar c√≥digo de sa√≠da baseado nos resultados
            if test_results.get('overall_status') == 'success':
                print("\nüéâ Todos os testes de performance passaram!")
                return 0
            elif test_results.get('overall_status') == 'needs_improvement':
                print("\n‚ö†Ô∏è  Alguns endpoints precisam de otimiza√ß√£o.")
                return 1
            else:
                print("\n‚ùå Falhas significativas nos testes de performance.")
                return 2
                
        except Exception as e:
            print(f"‚ùå Erro durante testes de performance: {e}")
            logger.error(f"Erro nos testes de performance: {e}")
            return 3

    if __name__ == "__main__":
        try:
            exit_code = main()
            sys.exit(exit_code)
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è  Testes interrompidos pelo usu√°rio")
            sys.exit(130)  # Standard exit code for Ctrl+C

except ImportError as e:
    print(f"‚ùå Erro de importa√ß√£o: {e}")
    print("\nüîß Testes b√°sicos de performance:")
    print("O sistema modularizado n√£o est√° dispon√≠vel.")
    print("Executando testes b√°sicos como fallback...")
    
    # Fallback para testes b√°sicos
    import time
    import requests
    from datetime import datetime

    def basic_performance_test():
        """Testes b√°sicos de performance como fallback."""
        print("\nüèÉ Testes B√°sicos de Performance")
        print("=" * 40)
        
        # Teste simples de resposta
        test_urls = [
            ("API Health", "http://localhost:8000/health"),
            ("API Root", "http://localhost:8000/"),
        ]
        
        results = []
        
        for name, url in test_urls:
            try:
                print(f"\nüîç Testando {name}...")
                
                # M√∫ltiplas requisi√ß√µes para m√©dia
                durations = []
                for i in range(3):
                    start_time = time.time()
                    response = requests.get(url, timeout=5)
                    duration = time.time() - start_time
                    durations.append(duration)
                
                avg_duration = sum(durations) / len(durations)
                
                print(f"   Tempo m√©dio: {avg_duration:.3f}s")
                print(f"   Status: {response.status_code}")
                
                # Avalia√ß√£o b√°sica
                if avg_duration < 1.0:
                    print("   ‚úÖ Performance adequada")
                    results.append(True)
                else:
                    print("   ‚ö†Ô∏è  Performance pode ser melhorada")
                    results.append(False)
                    
            except Exception as e:
                print(f"   ‚ùå Erro: {e}")
                results.append(False)
        
        # Resumo
        passed_tests = sum(results)
        total_tests = len(results)
        
        print(f"\nüìä Resumo: {passed_tests}/{total_tests} testes passaram")
        
        if passed_tests == total_tests:
            print("‚úÖ Todos os testes b√°sicos passaram")
            return 0
        else:
            print("‚ö†Ô∏è  Alguns testes precisam de aten√ß√£o")
            return 1

    if __name__ == "__main__":
        try:
            exit_code = basic_performance_test()
            sys.exit(exit_code)
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è  Testes interrompidos pelo usu√°rio")
            sys.exit(130)