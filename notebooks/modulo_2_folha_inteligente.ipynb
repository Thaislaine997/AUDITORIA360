{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "main-header",
   "metadata": {},
   "source": [
    "# M√≥dulo 2: Controle Mensal da Folha Inteligente - AUDITORIA360\n",
    "\n",
    "## üìã Vis√£o Geral\n",
    "\n",
    "Este notebook documenta e demonstra as funcionalidades do M√≥dulo 2, incluindo:\n",
    "- Importa√ß√£o de extratos de folha de pagamento em formato PDF\n",
    "- Processamento ass√≠ncrono usando OCR (substituto do Document AI)\n",
    "- Valida√ß√£o e mapeamento de dados\n",
    "- Armazenamento estruturado no banco de dados\n",
    "\n",
    "## üéØ Objetivos\n",
    "\n",
    "- Automatizar a extra√ß√£o de dados de PDFs de folha de pagamento\n",
    "- Implementar processamento ass√≠ncrono para arquivos grandes\n",
    "- Validar e mapear dados extra√≠dos para estrutura interna\n",
    "- Monitorar e reportar status de processamento\n",
    "\n",
    "## üìö Pr√©-requisitos\n",
    "\n",
    "- Python 3.8+\n",
    "- Bibliotecas: requests, pandas, streamlit, paddleocr\n",
    "- API AUDITORIA360 em execu√ß√£o\n",
    "- Arquivos PDF de folha de pagamento\n",
    "\n",
    "## üöÄ Como Usar\n",
    "\n",
    "1. Configure as vari√°veis de ambiente\n",
    "2. Execute as c√©lulas sequencialmente\n",
    "3. Fa√ßa upload do arquivo PDF\n",
    "4. Monitore o processamento\n",
    "5. Visualize os resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-section",
   "metadata": {},
   "source": [
    "## üîß Configura√ß√£o do Ambiente\n",
    "\n",
    "Configura√ß√£o inicial das bibliotecas, vari√°veis de ambiente e autentica√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import streamlit as st\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Suprimir warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes da API\n",
    "API_BASE_URL = os.getenv('API_BASE_URL', 'http://localhost:8000')\n",
    "CLIENT_ID = os.getenv('CLIENT_ID', '12345')\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ Ambiente configurado com sucesso!\")\n",
    "print(f\"üåê API Base URL: {API_BASE_URL}\")\n",
    "print(f\"üÜî Client ID: {CLIENT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upload-section",
   "metadata": {},
   "source": [
    "## üìÑ Upload e Processamento de PDF\n",
    "\n",
    "Interface para upload de arquivos PDF e in√≠cio do processamento ass√≠ncrono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pdf-upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_and_process_pdf(pdf_file_path, client_id=CLIENT_ID):\n",
    "    \"\"\"\n",
    "    Faz upload do arquivo PDF e inicia o processamento ass√≠ncrono.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file_path (str): Caminho para o arquivo PDF\n",
    "        client_id (str): ID do cliente\n",
    "    \n",
    "    Returns:\n",
    "        dict: Resposta da API com job_id se bem-sucedido\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar se o arquivo existe\n",
    "        if not os.path.exists(pdf_file_path):\n",
    "            print(f\"‚ùå Arquivo n√£o encontrado: {pdf_file_path}\")\n",
    "            print(\"üìù Criando arquivo de exemplo para demonstra√ß√£o...\")\n",
    "            \n",
    "            # Criar dados de exemplo em formato JSON para simular PDF processado\n",
    "            sample_data = {\n",
    "                \"funcionarios\": [\n",
    "                    {\n",
    "                        \"nome\": \"Jo√£o Silva Santos\",\n",
    "                        \"cpf\": \"123.456.789-00\",\n",
    "                        \"cargo\": \"Analista\",\n",
    "                        \"salario_base\": 5000.00,\n",
    "                        \"horas_extras\": 300.00,\n",
    "                        \"descontos\": 850.00,\n",
    "                        \"salario_liquido\": 4450.00\n",
    "                    },\n",
    "                    {\n",
    "                        \"nome\": \"Maria Oliveira Costa\",\n",
    "                        \"cpf\": \"987.654.321-00\",\n",
    "                        \"cargo\": \"Coordenadora\",\n",
    "                        \"salario_base\": 7500.00,\n",
    "                        \"horas_extras\": 500.00,\n",
    "                        \"descontos\": 1200.00,\n",
    "                        \"salario_liquido\": 6800.00\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            # Simular processamento bem-sucedido\n",
    "            job_id = f\"job_{int(time.time())}\"\n",
    "            print(f\"‚úÖ Processamento simulado iniciado com sucesso!\")\n",
    "            print(f\"üÜî Job ID: {job_id}\")\n",
    "            \n",
    "            return {\n",
    "                \"status\": \"success\",\n",
    "                \"job_id\": job_id,\n",
    "                \"message\": \"Processamento iniciado com sucesso\",\n",
    "                \"data\": sample_data\n",
    "            }\n",
    "        \n",
    "        # Processar arquivo real\n",
    "        with open(pdf_file_path, 'rb') as pdf_file:\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/api/v1/clientes/{client_id}/folhas/importar-pdf-async\",\n",
    "                files={\"file\": pdf_file},\n",
    "                timeout=30\n",
    "            )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            job_id = result.get(\"job_id\")\n",
    "            print(f\"‚úÖ Job iniciado com sucesso!\")\n",
    "            print(f\"üÜî Job ID: {job_id}\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao iniciar o job: {response.text}\")\n",
    "            return {\"status\": \"error\", \"message\": response.text}\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Erro de conex√£o: {str(e)}\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro inesperado: {str(e)}\")\n",
    "        return {\"status\": \"error\", \"message\": str(e)}\n",
    "\n",
    "# Exemplo de uso\n",
    "PDF_FILE_PATH = \"sample_extrato.pdf\"\n",
    "result = upload_and_process_pdf(PDF_FILE_PATH)\n",
    "\n",
    "# Armazenar job_id para uso posterior\n",
    "if result.get(\"status\") == \"success\":\n",
    "    CURRENT_JOB_ID = result.get(\"job_id\")\n",
    "    print(f\"\\nüìã Job ID armazenado: {CURRENT_JOB_ID}\")\n",
    "else:\n",
    "    CURRENT_JOB_ID = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitoring-section",
   "metadata": {},
   "source": [
    "## üîç Monitoramento do Processamento\n",
    "\n",
    "Fun√ß√µes para consultar o status do job e monitorar o progresso do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "job-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_job_status(job_id, client_id=CLIENT_ID, max_attempts=20):\n",
    "    \"\"\"\n",
    "    Consulta o status de um job de processamento.\n",
    "    \n",
    "    Args:\n",
    "        job_id (str): ID do job\n",
    "        client_id (str): ID do cliente\n",
    "        max_attempts (int): N√∫mero m√°ximo de tentativas\n",
    "    \n",
    "    Returns:\n",
    "        dict: Status final do job\n",
    "    \"\"\"\n",
    "    if not job_id:\n",
    "        print(\"‚ö†Ô∏è  Job ID n√£o fornecido. Simulando status...\")\n",
    "        return {\n",
    "            \"status\": \"CONCLUIDO_SUCESSO\",\n",
    "            \"message\": \"Processamento simulado conclu√≠do com sucesso\",\n",
    "            \"progress\": 100\n",
    "        }\n",
    "    \n",
    "    print(f\"üîç Monitorando job: {job_id}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    attempt = 0\n",
    "    while attempt < max_attempts:\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                f\"{API_BASE_URL}/api/v1/clientes/{client_id}/folhas/importar-pdf-async/status/{job_id}\",\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                job_data = response.json()\n",
    "                status = job_data.get(\"status\")\n",
    "                progress = job_data.get(\"progress\", 0)\n",
    "                \n",
    "                print(f\"üìä Tentativa {attempt + 1}: Status = {status} ({progress}%)\")\n",
    "                \n",
    "                # Status finais\n",
    "                if status in [\"CONCLUIDO_SUCESSO\", \"CONCLUIDO_COM_PENDENCIAS\", \"FALHA_DOCAI\", \"FALHA_MAPEAMENTO\"]:\n",
    "                    if status == \"CONCLUIDO_SUCESSO\":\n",
    "                        print(\"‚úÖ Processamento conclu√≠do com sucesso!\")\n",
    "                    elif status == \"CONCLUIDO_COM_PENDENCIAS\":\n",
    "                        print(\"‚ö†Ô∏è  Processamento conclu√≠do com pend√™ncias\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Falha no processamento: {status}\")\n",
    "                    \n",
    "                    return job_data\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Erro na consulta (tentativa {attempt + 1}): {response.text}\")\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ö†Ô∏è  Erro de conex√£o (tentativa {attempt + 1}): {str(e)}\")\n",
    "        \n",
    "        attempt += 1\n",
    "        if attempt < max_attempts:\n",
    "            print(\"‚è≥ Aguardando 5 segundos...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print(f\"‚è∞ Timeout: M√°ximo de tentativas ({max_attempts}) atingido\")\n",
    "    return {\"status\": \"TIMEOUT\", \"message\": \"Timeout na consulta do status\"}\n",
    "\n",
    "# Monitorar o job atual\n",
    "if CURRENT_JOB_ID:\n",
    "    final_status = check_job_status(CURRENT_JOB_ID)\n",
    "    print(f\"\\nüéØ Status final: {final_status}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhum job ativo para monitorar\")\n",
    "    final_status = check_job_status(None)  # Simular status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-section",
   "metadata": {},
   "source": [
    "## ‚úÖ Valida√ß√£o e Mapeamento de Dados\n",
    "\n",
    "Processamento dos dados extra√≠dos, valida√ß√£o e mapeamento para a estrutura interna do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_map_data(extracted_data):\n",
    "    \"\"\"\n",
    "    Valida e mapeia os dados extra√≠dos do PDF.\n",
    "    \n",
    "    Args:\n",
    "        extracted_data (dict): Dados extra√≠dos do processamento\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dados validados e mapeados\n",
    "    \"\"\"\n",
    "    print(\"üîç VALIDA√á√ÉO E MAPEAMENTO DE DADOS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Obter dados de exemplo ou dados reais\n",
    "    if not extracted_data or not extracted_data.get(\"funcionarios\"):\n",
    "        print(\"üìù Usando dados de exemplo para demonstra√ß√£o...\")\n",
    "        funcionarios_data = [\n",
    "            {\n",
    "                \"nome\": \"Jo√£o Silva Santos\",\n",
    "                \"cpf\": \"123.456.789-00\",\n",
    "                \"cargo\": \"Analista\",\n",
    "                \"salario_base\": 5000.00,\n",
    "                \"horas_extras\": 300.00,\n",
    "                \"descontos\": 850.00,\n",
    "                \"salario_liquido\": 4450.00\n",
    "            },\n",
    "            {\n",
    "                \"nome\": \"Maria Oliveira Costa\",\n",
    "                \"cpf\": \"987.654.321-00\",\n",
    "                \"cargo\": \"Coordenadora\",\n",
    "                \"salario_base\": 7500.00,\n",
    "                \"horas_extras\": 500.00,\n",
    "                \"descontos\": 1200.00,\n",
    "                \"salario_liquido\": 6800.00\n",
    "            },\n",
    "            {\n",
    "                \"nome\": \"Pedro Santos Lima\",\n",
    "                \"cpf\": \"456.789.123-00\",\n",
    "                \"cargo\": \"Gerente\",\n",
    "                \"salario_base\": 12000.00,\n",
    "                \"horas_extras\": 0.00,\n",
    "                \"descontos\": 2100.00,\n",
    "                \"salario_liquido\": 9900.00\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        funcionarios_data = extracted_data[\"funcionarios\"]\n",
    "    \n",
    "    # Criar DataFrame para valida√ß√£o\n",
    "    df = pd.DataFrame(funcionarios_data)\n",
    "    \n",
    "    print(f\"üìä Total de registros para validar: {len(df)}\")\n",
    "    \n",
    "    # Fun√ß√£o de valida√ß√£o\n",
    "    def validate_record(row):\n",
    "        errors = []\n",
    "        warnings = []\n",
    "        \n",
    "        # Validar CPF\n",
    "        if not row.get('cpf') or len(str(row['cpf']).replace('.', '').replace('-', '')) != 11:\n",
    "            errors.append(\"CPF inv√°lido ou ausente\")\n",
    "        \n",
    "        # Validar nome\n",
    "        if not row.get('nome') or len(str(row['nome']).strip()) < 3:\n",
    "            errors.append(\"Nome inv√°lido ou muito curto\")\n",
    "        \n",
    "        # Validar valores financeiros\n",
    "        if row.get('salario_base', 0) <= 0:\n",
    "            errors.append(\"Sal√°rio base deve ser maior que zero\")\n",
    "        \n",
    "        if row.get('salario_base', 0) < 1320:  # Sal√°rio m√≠nimo aproximado\n",
    "            warnings.append(\"Sal√°rio base abaixo do sal√°rio m√≠nimo\")\n",
    "        \n",
    "        if row.get('horas_extras', 0) < 0:\n",
    "            errors.append(\"Horas extras n√£o podem ser negativas\")\n",
    "        \n",
    "        if row.get('descontos', 0) < 0:\n",
    "            errors.append(\"Descontos n√£o podem ser negativos\")\n",
    "        \n",
    "        # Validar consist√™ncia do sal√°rio l√≠quido\n",
    "        calculated_liquido = row.get('salario_base', 0) + row.get('horas_extras', 0) - row.get('descontos', 0)\n",
    "        actual_liquido = row.get('salario_liquido', 0)\n",
    "        \n",
    "        if abs(calculated_liquido - actual_liquido) > 0.01:  # Toler√¢ncia de 1 centavo\n",
    "            warnings.append(f\"Inconsist√™ncia no sal√°rio l√≠quido (calculado: {calculated_liquido:.2f}, informado: {actual_liquido:.2f})\")\n",
    "        \n",
    "        return {\n",
    "            'errors': errors,\n",
    "            'warnings': warnings,\n",
    "            'is_valid': len(errors) == 0\n",
    "        }\n",
    "    \n",
    "    # Aplicar valida√ß√£o\n",
    "    validation_results = df.apply(validate_record, axis=1)\n",
    "    \n",
    "    # Adicionar resultados ao DataFrame\n",
    "    df['validation_errors'] = [result['errors'] for result in validation_results]\n",
    "    df['validation_warnings'] = [result['warnings'] for result in validation_results]\n",
    "    df['is_valid'] = [result['is_valid'] for result in validation_results]\n",
    "    \n",
    "    # Estat√≠sticas de valida√ß√£o\n",
    "    total_records = len(df)\n",
    "    valid_records = df['is_valid'].sum()\n",
    "    invalid_records = total_records - valid_records\n",
    "    \n",
    "    print(f\"\\nüìà Resultados da Valida√ß√£o:\")\n",
    "    print(f\"   ‚úÖ Registros v√°lidos: {valid_records} ({valid_records/total_records*100:.1f}%)\")\n",
    "    print(f\"   ‚ùå Registros inv√°lidos: {invalid_records} ({invalid_records/total_records*100:.1f}%)\")\n",
    "    \n",
    "    # Mostrar detalhes dos erros\n",
    "    if invalid_records > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Detalhes dos Erros:\")\n",
    "        invalid_df = df[~df['is_valid']]\n",
    "        for idx, row in invalid_df.iterrows():\n",
    "            print(f\"   ‚Ä¢ {row['nome']}: {', '.join(row['validation_errors'])}\")\n",
    "    \n",
    "    # Mostrar warnings\n",
    "    warnings_count = sum(len(w) for w in df['validation_warnings'])\n",
    "    if warnings_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Avisos encontrados: {warnings_count}\")\n",
    "        for idx, row in df.iterrows():\n",
    "            if row['validation_warnings']:\n",
    "                print(f\"   ‚Ä¢ {row['nome']}: {', '.join(row['validation_warnings'])}\")\n",
    "    \n",
    "    # Retornar dados validados\n",
    "    valid_data = df[df['is_valid']].drop(['validation_errors', 'validation_warnings', 'is_valid'], axis=1)\n",
    "    \n",
    "    return {\n",
    "        'all_data': df,\n",
    "        'valid_data': valid_data,\n",
    "        'validation_summary': {\n",
    "            'total_records': total_records,\n",
    "            'valid_records': valid_records,\n",
    "            'invalid_records': invalid_records,\n",
    "            'warnings_count': warnings_count\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Validar dados do resultado do processamento\n",
    "if 'result' in locals() and result.get('data'):\n",
    "    validation_result = validate_and_map_data(result['data'])\n",
    "else:\n",
    "    validation_result = validate_and_map_data(None)\n",
    "\n",
    "# Exibir dados v√°lidos\n",
    "print(f\"\\nüìã Dados V√°lidos para Armazenamento:\")\n",
    "if not validation_result['valid_data'].empty:\n",
    "    display(validation_result['valid_data'])\n",
    "else:\n",
    "    print(\"   ‚ùå Nenhum registro v√°lido encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-section",
   "metadata": {},
   "source": [
    "## üéØ Resumo do Processamento e Pr√≥ximos Passos\n",
    "\n",
    "### Principais Funcionalidades Demonstradas\n",
    "\n",
    "1. **Upload e Processamento**: Upload de PDF e in√≠cio do processamento ass√≠ncrono\n",
    "2. **Monitoramento**: Acompanhamento do status do job em tempo real\n",
    "3. **Valida√ß√£o**: Valida√ß√£o abrangente dos dados extra√≠dos\n",
    "4. **Armazenamento**: Persist√™ncia segura no banco de dados\n",
    "5. **Visualiza√ß√£o**: Dashboards e gr√°ficos para an√°lise\n",
    "\n",
    "### Arquitetura do Sistema\n",
    "\n",
    "```\n",
    "üìÑ PDF Upload ‚Üí üîÑ Processamento Ass√≠ncrono ‚Üí ‚úÖ Valida√ß√£o ‚Üí üíæ Armazenamento ‚Üí üìä Visualiza√ß√£o\n",
    "```\n",
    "\n",
    "### Benef√≠cios\n",
    "\n",
    "- **Automa√ß√£o**: Reduz trabalho manual de digita√ß√£o\n",
    "- **Precis√£o**: Valida√ß√£o autom√°tica de consist√™ncia\n",
    "- **Escalabilidade**: Processamento ass√≠ncrono para arquivos grandes\n",
    "- **Rastreabilidade**: Log completo de todas as opera√ß√µes\n",
    "- **Integra√ß√£o**: API compat√≠vel com sistemas existentes\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "1. **Integra√ß√£o com OCR Real**: Implementar PaddleOCR ou similar\n",
    "2. **Melhorias de UI**: Interface web mais amig√°vel\n",
    "3. **Alertas**: Notifica√ß√µes autom√°ticas de inconsist√™ncias\n",
    "4. **Relat√≥rios**: Gera√ß√£o autom√°tica de relat√≥rios de auditoria\n",
    "5. **Machine Learning**: Modelos preditivos para detec√ß√£o de fraudes\n",
    "\n",
    "### Documenta√ß√£o T√©cnica\n",
    "\n",
    "- **API Endpoints**: Consulte a documenta√ß√£o da API\n",
    "- **Schemas**: Estruturas de dados no arquivo de schemas\n",
    "- **Configura√ß√£o**: Vari√°veis de ambiente e configura√ß√µes\n",
    "- **Logs**: Sistema de logging estruturado\n",
    "\n",
    "---\n",
    "\n",
    "**üìÖ √öltima atualiza√ß√£o**: Janeiro 2025  \n",
    "**üë®‚Äçüíª Desenvolvido por**: Equipe AUDITORIA360  \n",
    "**üìß Suporte**: Consulte a documenta√ß√£o t√©cnica ou entre em contato com a equipe de desenvolvimento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
