{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf367fd",
   "metadata": {},
   "source": [
    "# Épico 2.1: Importação e Extração de Dados de Extratos de Folha de Pagamento\n",
    "\n",
    "Este notebook documenta e prototipa as funcionalidades relacionadas à importação e extração de dados de extratos de folha de pagamento, com foco no uso do Document AI para processar PDFs e no armazenamento dos dados extraídos no BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f774b283",
   "metadata": {},
   "source": [
    "# Módulo 2: Controle Mensal da Folha Inteligente\n",
    "\n",
    "Este notebook documenta e prototipa as funcionalidades do Módulo 2, incluindo a importação de extratos de folha de pagamento em formato PDF, processamento assíncrono usando o Document AI e armazenamento no BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac9798",
   "metadata": {},
   "source": [
    "# Processamento Assíncrono do PDF\n",
    "\n",
    "Nesta seção, será demonstrado como o sistema realiza o processamento assíncrono de arquivos PDF utilizando o Document AI e integra os resultados ao BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Configurações\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "CLIENT_ID = \"12345\"\n",
    "PDF_FILE_PATH = \"sample_extrato.pdf\"\n",
    "\n",
    "# Enviar PDF para processamento\n",
    "with open(PDF_FILE_PATH, 'rb') as pdf_file:\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/api/v1/clientes/{CLIENT_ID}/folhas/importar-pdf-async\",\n",
    "        files={\"file\": pdf_file}\n",
    "    )\n",
    "\n",
    "if response.status_code == 200:\n",
    "    job_id = response.json().get(\"job_id\")\n",
    "    print(f\"Job iniciado com sucesso. ID do Job: {job_id}\")\n",
    "else:\n",
    "    print(f\"Erro ao iniciar o job: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52534b1a",
   "metadata": {},
   "source": [
    "# Configuração do Ambiente\n",
    "\n",
    "Nesta seção, configuramos as bibliotecas necessárias, autenticação com Google Cloud e inicializamos variáveis globais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Configurar autenticação com Google Cloud\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'path/to/your-service-account-key.json'\n",
    ")\n",
    "client = storage.Client(credentials=credentials)\n",
    "\n",
    "# Inicializar variáveis globais\n",
    "BUCKET_NAME = 'seu-bucket-folhas-clientes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f838d321",
   "metadata": {},
   "source": [
    "# Upload de Arquivo PDF\n",
    "\n",
    "Nesta seção, implementamos a interface para upload de arquivos PDF usando Streamlit e salvamos os arquivos no Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Interface para upload de arquivos PDF\n",
    "st.title(\"Upload de Arquivo PDF\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Selecione o arquivo PDF:\", type=[\"pdf\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    st.write(\"Arquivo carregado com sucesso!\")\n",
    "    # Salvar o arquivo no Google Cloud Storage\n",
    "    bucket = client.bucket(BUCKET_NAME)\n",
    "    blob = bucket.blob(f\"uploads/{uploaded_file.name}\")\n",
    "    blob.upload_from_file(uploaded_file)\n",
    "    st.success(f\"Arquivo {uploaded_file.name} salvo no bucket {BUCKET_NAME}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23979aee",
   "metadata": {},
   "source": [
    "# Mapeamento e Validação de Dados\n",
    "\n",
    "Nesta seção, será demonstrado como os dados extraídos do PDF são mapeados para a estrutura interna do sistema e validados antes de serem armazenados no BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5cedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulação de dados extraídos do Document AI\n",
    "data_extracted = [\n",
    "    {\"funcionario_nome\": \"João Silva\", \"cpf\": \"123.456.789-00\", \"rubrica\": \"Salário\", \"valor\": 5000.00},\n",
    "    {\"funcionario_nome\": \"Maria Oliveira\", \"cpf\": \"987.654.321-00\", \"rubrica\": \"Vale Transporte\", \"valor\": -150.00},\n",
    "]\n",
    "\n",
    "# Criar DataFrame para validação\n",
    "df = pd.DataFrame(data_extracted)\n",
    "\n",
    "# Validação de dados\n",
    "def validate_data(row):\n",
    "    errors = []\n",
    "    if not row['cpf']:\n",
    "        errors.append(\"CPF ausente\")\n",
    "    if row['valor'] <= 0:\n",
    "        errors.append(\"Valor inválido\")\n",
    "    return errors\n",
    "\n",
    "df['erros'] = df.apply(validate_data, axis=1)\n",
    "\n",
    "# Exibir resultados de validação\n",
    "print(\"Dados validados:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab2f4f",
   "metadata": {},
   "source": [
    "# Armazenamento no BigQuery\n",
    "\n",
    "Nesta seção, será demonstrado como os dados validados são armazenados no BigQuery, utilizando a biblioteca `google-cloud-bigquery` para interagir com o serviço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaab7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Configurar cliente do BigQuery\n",
    "client = bigquery.Client()\n",
    "\n",
    "def insert_into_bigquery(dataset_id, table_id, rows_to_insert):\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "    if errors:\n",
    "        print(f\"Erros ao inserir no BigQuery: {errors}\")\n",
    "    else:\n",
    "        print(\"Dados inseridos com sucesso no BigQuery.\")\n",
    "\n",
    "# Dados validados para inserção\n",
    "data_to_insert = [\n",
    "    {\"funcionario_nome\": \"João Silva\", \"cpf\": \"123.456.789-00\", \"rubrica\": \"Salário\", \"valor\": 5000.00},\n",
    "    {\"funcionario_nome\": \"Maria Oliveira\", \"cpf\": \"987.654.321-00\", \"rubrica\": \"Vale Transporte\", \"valor\": -150.00},\n",
    "]\n",
    "\n",
    "# Inserir dados no BigQuery\n",
    "insert_into_bigquery(\"auditoria_folha_dataset\", \"LinhasFolhaFuncionario\", data_to_insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877c05a",
   "metadata": {},
   "source": [
    "# Consulta de Status do Job\n",
    "\n",
    "Nesta seção, será demonstrado como consultar o status de um job de processamento assíncrono utilizando a API do backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e000282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Função para consultar o status do job\n",
    "def check_job_status(job_id):\n",
    "    while True:\n",
    "        response = requests.get(f\"{API_BASE_URL}/api/v1/clientes/{CLIENT_ID}/folhas/importar-pdf-async/status/{job_id}\")\n",
    "        if response.status_code == 200:\n",
    "            status = response.json().get(\"status\")\n",
    "            print(f\"Status do Job: {status}\")\n",
    "            if status in [\"CONCLUIDO_SUCESSO\", \"CONCLUIDO_COM_PENDENCIAS\", \"FALHA_DOCAI\", \"FALHA_MAPEAMENTO\"]:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"Erro ao consultar status: {response.text}\")\n",
    "            break\n",
    "        time.sleep(5)  # Aguardar 5 segundos antes de consultar novamente\n",
    "\n",
    "# Exemplo de uso\n",
    "job_id = \"exemplo_job_id\"  # Substituir pelo ID real do job\n",
    "check_job_status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce0370",
   "metadata": {},
   "source": [
    "# Visualização de Resultados\n",
    "\n",
    "Nesta seção, será demonstrado como visualizar os resultados processados e armazenados no BigQuery, utilizando gráficos e tabelas interativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Simulação de dados processados\n",
    "data_processed = [\n",
    "    {\"funcionario_nome\": \"João Silva\", \"rubrica\": \"Salário\", \"valor\": 5000.00},\n",
    "    {\"funcionario_nome\": \"Maria Oliveira\", \"rubrica\": \"Vale Transporte\", \"valor\": -150.00},\n",
    "]\n",
    "\n",
    "# Criar DataFrame para visualização\n",
    "df_processed = pd.DataFrame(data_processed)\n",
    "\n",
    "# Exibir tabela de resultados\n",
    "print(\"Resultados Processados:\")\n",
    "print(df_processed)\n",
    "\n",
    "# Gráfico de barras para valores por funcionário\n",
    "df_processed.groupby(\"funcionario_nome\")[\"valor\"].sum().plot(kind=\"bar\", title=\"Valores por Funcionário\")\n",
    "plt.xlabel(\"Funcionário\")\n",
    "plt.ylabel(\"Valor (R$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829c9e6",
   "metadata": {},
   "source": [
    "# Tratamento de Erros\n",
    "\n",
    "Nesta seção, será demonstrado como identificar e tratar erros ocorridos durante o processamento, utilizando logs e mensagens de erro detalhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06149365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulação de erros durante o processamento\n",
    "def process_data_with_error_handling(data):\n",
    "    for record in data:\n",
    "        try:\n",
    "            # Simular processamento\n",
    "            if record.get(\"valor\") < 0:\n",
    "                raise ValueError(f\"Valor inválido para {record['funcionario_nome']}: {record['valor']}\")\n",
    "            print(f\"Processado com sucesso: {record}\")\n",
    "        except ValueError as ve:\n",
    "            print(f\"Erro de valor: {ve}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro inesperado: {e}\")\n",
    "\n",
    "# Dados de exemplo com erro\n",
    "data_with_errors = [\n",
    "    {\"funcionario_nome\": \"João Silva\", \"valor\": 5000.00},\n",
    "    {\"funcionario_nome\": \"Maria Oliveira\", \"valor\": -150.00},\n",
    "]\n",
    "\n",
    "# Processar dados com tratamento de erros\n",
    "process_data_with_error_handling(data_with_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f49dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do Ambiente\n",
    "import os\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Configurar autenticação do Google Cloud\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your-service-account-key.json'\n",
    "\n",
    "# Variáveis globais\n",
    "PROJECT_ID = 'seu-projeto-id'\n",
    "BUCKET_NAME = 'seu-bucket-name'\n",
    "PROCESSOR_ID = 'seu-processor-id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do Document AI\n",
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "# Configurações iniciais\n",
    "PROJECT_ID = \"seu-projeto-id\"\n",
    "LOCATION = \"us\"  # Localização do processador\n",
    "PROCESSOR_ID = \"seu-processor-id\"  # ID do processador configurado no Document AI\n",
    "\n",
    "# Inicializar cliente do Document AI\n",
    "docai_client = documentai.DocumentProcessorServiceClient()\n",
    "\n",
    "# Caminho do processador\n",
    "processor_path = docai_client.processor_path(PROJECT_ID, LOCATION, PROCESSOR_ID)\n",
    "\n",
    "print(f\"Processador configurado: {processor_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c328d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para processar PDF com Document AI\n",
    "from google.cloud.documentai_v1beta3.types import GcsDocument\n",
    "from google.cloud.documentai_v1beta3.types import BatchDocumentsInputConfig\n",
    "\n",
    "def process_pdf_with_docai(gcs_uri):\n",
    "    # Configurar documento no GCS\n",
    "    gcs_document = GcsDocument(gcs_uri=gcs_uri, mime_type=\"application/pdf\")\n",
    "    input_config = BatchDocumentsInputConfig(gcs_documents={\"documents\": [gcs_document]})\n",
    "\n",
    "    # Criar requisição\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=processor_path,\n",
    "        raw_document=None,\n",
    "        input_documents=input_config,\n",
    "        skip_human_review=True\n",
    "    )\n",
    "\n",
    "    # Processar documento\n",
    "    result = docai_client.process_document(request=request)\n",
    "    document = result.document\n",
    "\n",
    "    print(\"Processamento concluído com sucesso!\")\n",
    "    return document\n",
    "\n",
    "# Exemplo de uso\n",
    "gcs_uri_example = \"gs://seu-bucket/exemplo.pdf\"\n",
    "document_result = process_pdf_with_docai(gcs_uri_example)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
